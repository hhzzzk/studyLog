# CV_SIFT_상세

## 디스크립터 descriptor

주어진 특징점을 기준으로 주변에 있는 정보로 주변 정보나 구조를 알아보는 것이다.

특징을 검출한 후에 이러한 특징을 잘 나타내기 위한 표현 방법이 필요하다.

이를 디스크립터라고 한다.

디스크립터는 해당 특징점을 묘사하고 나타내는데 사용되며 일반적으로 벡터 형태로 표현된다.

## Alignment

서로 다른 두 개의 영상을 정렬하고 일치시키는 과정이다.

*두 영상 사이의 이동, 회전, 스케일, 조명 정보 등의 변환 정보를 알아낸다.*

이를 통해 두 이미지 간의 관계를 이해하고 상대적인 위치 및 구조를 파악할 수 있다.

주로 호모그래피를 활용해 수행되는데 호모그래피는 한 이미지를 다른 이미지에 정확하게 매핑하기 위해 사용되는 변환 기법이다.

- 매칭되는 영상을 찾아 그 영상에 r,t,s를 얼만큼 했는지 알아낸다. 그리고 합친다. 

  여기서 그런 r,t,s의 변환을 맞춰주는 것이 alignment이다.

## 개요

시프트 매칭은 주로 파노라마 이미지 구축에 사용된다. 이미지를 매칭, align 하는 과정을 거친다.

이미지가 섞여있어도 찾아낼 수 있다. 

그러나 이미지를 맞추는 과정에서 일부 손실되는 부분이 있을 수 있다.

![image](https://github.com/hhzzzk/studyLog/assets/67236054/0e06844a-9dd5-4f72-ac23-25f715d06a93)

## 특징점 매칭하기

![image](https://github.com/hhzzzk/studyLog/assets/67236054/96681d43-8bb1-4808-a875-e9fa941034a1)

1단계, 먼저 각 이미지에서 독립적으로(비교X), 특징점들을 찾는다.

![image](https://github.com/hhzzzk/studyLog/assets/67236054/413c52cc-cb75-46b9-a7af-717d1ab39248)

2단계, 찾아낸 특징들을 가지고 다른 영상에서 매칭되는 짝꿍을 찾는다.

- 나와 같은 특징점을 가진 것이 누구인지 찾는다. 이 때 Local feature가 사용된다.

  - 로컬 피처는 내 특징점을 기준으로 *주변의 정보를 가지*고 나와 유사한 주변 정보를 가진 것이 누군지 찾자.

- 이 때 필요한 것이 reliable, distinctive한 descriptor

  - 디스크립터는 가진 특징을 잘 나타내는 하나의 이름표. 표현법

  - reliable : 해당 특징에 대해 항상 a라고 부를 수 있어야 한다.

  - distinctive : 뚜렷하게 구분되는. 다른 사람과 구분되는 이름을 지어야 한다.

    ​			해당 이름으로 어디에서도 얘를 찾을 수 있는

​	

---

![image](https://github.com/hhzzzk/studyLog/assets/67236054/184e6b36-2a37-4f24-8634-8237a793f777)

특징점들이 다양한 분야에서 쓰인다.



## SIFT 알고리즘 4단계

1. 키포인트 찾기
2. dominant orientation 찾기
3. compute their descriptor
4. match them on other images


---

1. 키포인트는 주어진 영상에서 가장 관심있는 점.
   - 주어진 도메인에서 로컬 미니멈이나 맥시멈 찾기. 그 방법이 피라미드 이미지에서 DoG차이로 찾는다.
2. 각 키포인트를 중심으로 주어진 영역의 로컬 영역에 대해 키포인트가 어느 방향, 그래디언트가 많이 변하는지 찾는다. 그것이 dominant 오리엔테이션이다.
3. 키포인트의 도미넌트 오리엔테이션 방향으로 각 키포인트에게 이름을 붙인 디스크립터로 표현한다.

- 시프트알고리즘 특징점 찾고 매칭 == 각 키포인트의 도미넌트 오리엔테이션 정보로 이름 붙이고 각 영상에서 동일한 특징점 기준으로 방향 같은 것들을 매칭하는 것

---

## 시프트

![image](https://github.com/hhzzzk/studyLog/assets/67236054/30020809-13e3-4452-9bf9-c5465bb5c30a)

first octavev(옥타브) : 다차원 다해상도 가진 피라미드 이미지를 기반으로 만든 첫번째 다 해상도 영상

여러 옥타브 영상 만든다.

첫번째 옥타브 영상에서 가오시안 필터의 시그마 값 달리한 가오시안 영상들을 만든다.

그리고 각 가오시안 영상들의 차 값을 뺀 영상을 만든다. == DoG



이렇게 각 오타브의 DoG를 구하고 주변 영역과 위의 영상들로 로컬 미니멈과 맥시멈 찾는다.

이게 키포인트.



## 왜 DoG를 하는가?

에지영역에서 영교차 알고리즘 배웠다. 

노이즈를 줄이려고 가우시안 필터를 씌우면서 동시에 명암 차이가 많이 나는 영역을 뽑는다 == 영교차 알고리즘

그를 위해 주어진 영상에 가오시안 필터를 씌우고, 씌운 영상에 두 번 편미분을 하면 영교차 지점 나온다.

해당 지점들을 찾아 연결하면 엣지 영역을 뽑을 수 있다.

![image](https://github.com/hhzzzk/studyLog/assets/67236054/5eb02d06-04cc-4ca5-8209-e148c5690ebd)



이와 유사하게 주어진 영상에 대해 2차원 미분, x,y축으로 편미분한 것을 라플라시안 오퍼레이터라고 했다.

라플라시안 오퍼레이터 필터를 씌워서 0과 만나는 지점을 찾으면 그게 명암 차이가 많이 생기는 영역들.

엣지나 코너도 포함되어 있을 것이다. ~

## 라플라시안

[참고](https://100s.tistory.com/42)

∇*(∇⨍)

2차 도함수를 이용해 이미지의 밝기 변화를 감지한다. 엣지 코너 등의 고주파 성분 찾기에 유용하다.

∇*(∇⨍) : 그래디언트의 다이버전스다.

![img](https://blog.kakaocdn.net/dn/ugZr0/btrgwKf4spS/tJuC8l2k7BahJ6lLSKFtJ1/img.png)

gradien 연산자 ∇⨍ : 벡터 함수로 정의하는 벡터장 내의 한 점에서 벡터 함수의 값이 가장 급격히 변하는 주변의 위치와 크기를 알려준다.

Divergence 연산자(∇\*⨍) : 단위 단면적으로부터 퍼져 나가는 정도를 알려준다. 다이버전스가 0이라면 퍼져 나가는 정도와 유입되는 정도가 동일하므로 벡터의 흐름이 균일하다.

엣지 검출할 때 사용한다. 

## 라플라시안 근사 = DoG



![image](https://github.com/hhzzzk/studyLog/assets/67236054/935e6c7e-f3f2-4e95-be05-31ff03513649)

G는 가우시안 필터를 의미

(∇^2)G는 가우시안 필터의 라플라시안 = GL

L은 입력이미지를 필터링한 결과

D는 DoG이다.

1. GL은 가우시안을 시그마에 대해 편미분한 것의 근사로 나타난다.
   - 이는 가우시안 필터는 시그마와 시그마의 k배, 두 가지 크기로 적용한 후 그 차이를 (k-1)σ로 나눈 값으로 근사된다.
2. 두 가우시안 필터의 차이는 ==  (k-1)에 시그마제곱과 GL을 곱한 값으로 차이를 근사할 수 있다.
3. 두 가우시안 필터로 필터링한 이미지를 DoG로 계산한 것이다.
   - 결국 이는 라플라시안의 근사값으로 사용될 수 있다. ?



**피라미드 영상도 많은데 각 피라미드 영상마다 또 다르게 시그마해서 영상끼리 빼서 하려면 굉장히 시간이 오래 걸리는데 라플라시안 필터를 사용하면 빠르게 할 수 있다.**

---

![image](https://github.com/hhzzzk/studyLog/assets/67236054/db880441-867c-4d74-b383-32ed2bb8e9e1)

그림처럼 DoG하게 되면 flat은 날아가는데 엣지나 코너는 보인다.

![image](https://github.com/hhzzzk/studyLog/assets/67236054/2770fb16-2ed4-49b2-a884-f7b35bc1f80a)



## 극점 extrema 찾기

![image](https://github.com/hhzzzk/studyLog/assets/67236054/4e0b0ae8-a8b6-41a1-b15c-3ca93a98ae2c)

DoG를 만든다. 극값은 로컬 미니멈, 맥시멈이다. DoG에서 8연결성으로 극점을 찾는다.

그러면 우측의 키포인트 후보들, 찾아낸 극점들을 표시한 것이다.

## 스케일의 변화에 강인한 키포인트(극점) 찾기

![image](https://github.com/hhzzzk/studyLog/assets/67236054/2a69b2e5-903a-4edb-89fe-3e7f70ec4a34)

피라미드 이미지로 스케일의 변화를 만들면서

여전히 키포인트로 남아있는, 극점으로 남아있는 점들이 또 키포인트 후보들이다.



## 키포인트 후보들 지우기

![image](https://github.com/hhzzzk/studyLog/assets/67236054/c3a582c8-b7bb-4457-8b4a-ca8e451efe3d)

remove low contrast : 대비(차이)가 작은 후보들을 제거한다. 배경의 키포인트들을 제거한다. 

remove edges : 엣지에 해당하는 후보들을 제거한다. 이를 위해 이미지 그래디언트를 계산해 값이 높은 부분을 엣지로 간주하고 그런다.



## 도미넌트 오리엔테이션 찾기

![image](https://github.com/hhzzzk/studyLog/assets/67236054/e990c993-6f5b-41d9-b6cd-f1a4b76ebdec)

시프트는 회전에 강인한 특징 가져야 하는데 따라서 각 키포인트는 하나 이상의 지배적인 방향을 가진다. (강한 방향성..!)

이는 회전 불변성에 중요하다.



1. 키포인트 근방 영역에서 각 픽셀의 그래디언트 크기와 방향을 계산한다.
   - 영상에서의 밝기 변화와 방향을 나타내는데 사용된다.
   - 키포인트 근방의 영역은 키포인트의 크기와 스케일에 따라 다르게 결정된다.
2. 이미지 근방에서 계산된 그래디언트 방향을 기반으로 **히스토그램**을 구성한다.
   - 히스토그램은 각 방향간의 그래디언트 분포를 나타낸다.
   - 키포인트 근방의 방향성 파악에 사용된다.
3. 구성된 히스토그램에서 높은 피크를 가지는 방향들이 키포인트의 지배적인 방향으로 할당된다.
   - 이를 위해 각 포인트는 그 주변에서 가장 중요한 방향을 특정할 수 있다.

---

## a. 이미지 그래디언트와 오리앤테이션 계산

![image](https://github.com/hhzzzk/studyLog/assets/67236054/1eafdb95-6229-4771-958f-cb3be77d1d8b)

픽셀 위치 (x,y)에서 그래디언트의 크기는 m, 방향은 세타. L은 이미지에서의 픽셀 값이다. 라플라시안 기본

- m은 주어진 위치에서의 그래디언트 크기이다. 해당 위치의 가로 방향과 세로 방향의 픽셀 값 차이의 제곱근으로 계산된다. 해당 위치에서의 밝기 변화의 강도를 나타낸다.
- θ는 해당 위치에서의 가로 방향과 세로 방향의 픽셀 값 차이의 비율의 아크탄젠트를 계산해서 방향을 나타낸다. 해당 위치에서의 밝기 변화 방향을 파악할 수 있다.





## b. 방향 히스토그램

![image](https://github.com/hhzzzk/studyLog/assets/67236054/8d03c0d5-5692-45a8-a268-c4ca4633132c)

가운데 점을 기준으로 상하좌우로 4씩, 64개의 픽셀을 찾는다.

64개 각 픽셀의 도미넌트한 오리엔테이션 방향을 찾는다. 

각 아크탄젠트를 계산하면 0-360도 표현 가능, 이를 위처럼 8개의 방향으로 표현한다. 360/8

각 픽셀이 해당 방향 중 어디에 속하는지 보고 개수를 카운트해 히스토그램을 완성한다.

즉 히스토그램의 분포가 키포인트를 나타내는 특징 값 디스크립터로 표현된다.

히스토그램에서 가장 카운트가 많은, 자주 등장하는 방향이 *피크*가 되는 오리엔테이션이다.

![image](https://github.com/hhzzzk/studyLog/assets/67236054/d39c6625-2fb5-442d-b7ec-f6eb8c69309d)

이를 확장시킨다!!! ㅠ그만....멈춰줘..

![image](https://github.com/hhzzzk/studyLog/assets/67236054/abcddda4-3051-49d6-9da6-6f4e28654c26)

하나의 키포인트를 기준으로 16,16개의 이웃 픽셀들을 본다.

4,4 16개씩 해서 하나의 블럭으로 나눈다. 16개의 블럭.

각 블럭의 히스토그램의 분포를 본다. 

각 히스토그램마다 8개의 방향으로 표현하고 도미넌트한 오리앤테이션 방향을 다 찾는다.

이를 키포인트에 대한 디스크립터로 표현한다. 

블럭마다 8개의 방향이고 블럭은 16개이므로 == 128개의 차원, 디맨션으로 나타난다.

## 사용 결과

![image](https://github.com/hhzzzk/studyLog/assets/67236054/cd457c6e-3a68-4b9a-b42a-7d72497da1ab)

