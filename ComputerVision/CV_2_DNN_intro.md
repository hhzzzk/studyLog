# CV_2_DNN_intro

## 지도 학습 supervised learning

지도 학습은 각 입력에 대응하는 출력이나 레이블이 제공된 데이터 세트에서 알고리즘을 훈련시키는 머신러닝의 종류이다. 즉 입력과 정답값이 함께 주어진다.



지도 학습의 목표는 입력에서 출력으로의 매핑을 학습해 새로운 입력에 대해 모델이 정확한 예측이나 분류를 수행하는 것이다.



이전에 3개의 클래스에 대한 고야이 데이터 결과 고양이일 확률이 13프로고 차일 확률이 87퍼였다. 

그러나 정답은 첫번째 클래스가 1로 정답이었다. 이런게 지도학습





# Lecture 5 : Neural Networks

문제는 선형 분류기가 그렇게 강력하지 않다는 것이다.

선형 분류기는 각 클래스에 대해 하나의 템플릿을 사용하므로 한계가 있다.

- 선형 분류기를 이용하면 데이터의 선형적 특징을 잘 분리하지만 비선형성은 한계가 있다.
- visual viewpoint : 각 클래스에 대해 하나의 템플릿을 사용한다는 것은 데이터의 다양한 특성 반영이 어렵다. 

암튼 비선형적 특징을 해결해야 한다



## sol1) Feature Transforms

특징 변환은 입력 데이터의 특징을 새로운 형태로 변환한다. 

![image](https://github.com/hhzzzk/studyLog/assets/67236054/b1f89c63-9ca8-400b-9a0f-5208cfafecdc)

기존 데이터가 원형의 형태로 분포되어 있어 선형적으로 분리가 어려웠다면

새로운 입력 공간으로 변환하면서 해당 공간에서는 선형적으로 분리가 가능해지도록 데이터를 변환할 수 있다.



## sol2) Neural Networks

이전까지 다룬 선형 분류기, 스코어를 매긴 함수를 신경망으로 진화시키는 것이다!!!

이전까지는 층이 1개였다면 이제는 레이어를 추가해 2,3층의 신경망을 구성한다.

여러 층으로 구성하며 비선형성을 추가하기 위해 활성함수로 렐루 함수 등을 사용한다.

이러한 신경망은 입력층, 은닉층들, 출력층으로 구성된다.

![image](https://github.com/hhzzzk/studyLog/assets/67236054/323b1f9f-809b-4f37-af2c-486a02d4391d)



각 층에서는 선형+비선형 연산이 수행된다. 가중치와 입력을 내적하는 선형연산과 활성함수를 적용하는 비선형 연산이 이뤄진다.

은닉층을 추가하면 모델은 더 복잡한 함수를 근사화 가능해진다.



비선형 활성함수를 추가하지 않으면 함수는 선형연산이므로 선형연산을 무한개로 추가해도 선형성을 벗어날 수 없다.

![image](https://github.com/hhzzzk/studyLog/assets/67236054/dd105863-5a20-495c-a49a-4e8b5de49eca)

fully-connected 신경망은 모든 뉴런이 이전 및 다음 레이어의 모든 뉴런과 연결된 구조이다.

이 구조를 복잡한 문제에 대한 모델의 표현 능력을 높이는데 도움이 된다.

MLP는 이러한 신경망의 구조를 나타내는 용어 중 하나이다.