# CV_modelcomp

## Knowledge Distillation (Model compression)

지식 증류는 모델 압축 기술이다. 큰 규모의 복잡한 모델을 더 작고 간단한 모델로 전이시키기

- 학습된 pretrained된 큰 모델=선생님 모델이 가지고 있는 지식을 작은 모델=학생 모델에게 전달하여 성능을 유지하며 모델의 크기와 추론 속도를 향상시킨다.

![image](https://github.com/hhzzzk/studyLog/assets/67236054/db5aa201-5549-4617-a179-e2e90f288348)





## 소프트맥스 이용

![image](https://github.com/hhzzzk/studyLog/assets/67236054/c280f80f-1e6b-4f6f-b777-ab837423594d)

소프트맥스 함수는 logit 값을 정규화해 각 클래스에 속할 확률을 계산한다. 로짓 값이 높은 클래스일수록 해당 클래스에 속할 확률이 높아진다. 

- 소프트맥스 함수는 모든 클래스에 대한 확률을 정규화해 총합이 1이 된다.

https://deep-learning-study.tistory.com/699



T 온도 temperture변수는 소프트맥스 함수의 출력을 조절한다. 높은 온도일수록 출력 확률이 균등해지고 낮은 온도일수록 확률 차이가 커진다.

- 지식 증류에서 선생님 모델의 정보를 학생 모델에게 전달하기 위해 사용. 큰 모델에서 나온 소프트 타겟 = 선생님의 출력이 학생 모델을 학습하는데 사용된다.
- T값이 크면 선생님 모델의 출력이 평평해진다=특성 더 많이 본다. 학생 모델이 선생님 모델의 더 많은 특징을 학습
  - 평평한 분포는 모든 클래스에 대해 비슷한 확률을 부여하므로, 학생 모델이 더 다양한 특징을 학습하도록 유도할 수 있습니다.

> 선생님 모델의 확률 분포 = 소프트 타겟을 학생 모델이 잘 학습하도록 소프트맥스 함수의 온도 조절하는 것이 지식 증류

```
 knowledge distillation은 Soft label 방식을 사용하여 지식을 증류합니다. 사전에 학습된 teacher model로부터 soft label을 출력합니다. soft label은 정답일 확률이 [0.1, 0.2, 0.3, 0.05] 처럼 극단적인 값을 갖지 않습니다. 정답 이외의 확률이 존재하여 해당 이미지에서 더 많은 정보를 추출합니다. 더 많은 정보를 갖고 있는 soft label을 사용하여 student model을 학습합니다.

 반면에, hard label은 [0,0,1,0] 처럼 정답일 확률이 극단적인 값을 갖는 label 입니다. 정답이외에 다른 정보를 포함하지 않습니다.

 위 식에서 T는 temparature을 의미합니다. T가 높으면 soft label을 출력하고, T=1이면 hard label을 출력합니다.
 
```



## Attention map

![image](https://github.com/hhzzzk/studyLog/assets/67236054/feec62c0-c7b9-4bdd-aa48-2abc682dfa93)

어텐션 맵은 픽셀 간의 중요도를 나타내는 지도로 각 픽셀에 대한 가중치를 결정하는데 사용

= 모델이 입력 데이터의 어떤 부분에 주의를 기울였는지 시각적으로 나타내는 지도

생성방법 2가지

1. 전체 픽셀의 값을 더해 한장의 맵 생성 == 입력 이미지의 전역적인 특징 강조
2. 가로세로 방향으로 절대값으로 더한 맵 생성
   - 입력에서 각 픽셀의 값을 가로 및 세로 방향으로 절대값 취해 더하고 한장의 맵 생성
   - 각 픽셀의 주변 픽셀들과의 차이 나타낸다. 주로 가로 및 세로 방향의 에지와 윤곽을 강조
   - 픽셀 간의 차이가 큰 부분은 해당 방향의 중요도가 높다고 해석 가능

![image](https://github.com/hhzzzk/studyLog/assets/67236054/6dd25e01-712d-4551-ba49-b9fb0b7cac88)

**Attention Transfer**

- 선생님 모델의 어텐션 정보를 학생 모델에게 전달하는 과정
- 선생님 모델의 어텐션 맵을 사용해 학생 모델을 학습시킴
- 학생 모델은 선생님 모델이 주목하는 부분에 더 많은 주의를 기울이며 학습한다.



## Factor trasnfer

선생님 모델과 학생 모델로 데이터를 전송할 때 네트워크 구조, 채널수, 초기 조건 등의 문제로 전송에 한계가 있다.



KD와 AT와 달리 FT 팩터 트랜스퍼는 직접적으로 출력을 비교하지 않는다.

- 선생님과 학생 네트워크에서 요소를 추출하고 이들 간의 차이를 최소화한다.
- 이 작업은 두 개의 컨볼루션 모듈을 사용해 수행. 이들은 각각 패러프레이즈와 트랜스레이어이다.
  - paraphraser : 선생님과 학생에서 특징을 추출하는 모듈
  - translator : 패러프레이저로 추출된 특징 간의 차이를 최소화하려는 모듈, 차이를 최소화해 선생님에서 학습한 특징을 학생에게 전달

![image](https://github.com/hhzzzk/studyLog/assets/67236054/4e8d40dc-0f9a-47a6-a9db-95d5e97f0ae5)



## FT – Proposed method

![image](https://github.com/hhzzzk/studyLog/assets/67236054/8a865a0b-715d-4c88-a4b0-89ab381a8361)

Autoendoer 구조 : 오토인코더는 입력 데이터를 효과적으로 인코딩하고 그걸 기반으로 원본 입력을 재구성하는 네트워크이다. 주로 비지도 학습에서 사용, 중요한 특징 학습

패러프레이즈의 훈련

- 패러프레이저를 오토인코더 구조로 설계해 학습한다.
- 입력 데이터를 패러프레이저에 주입하고 패러프레이저는 입력을 압축해 중요한 특징이 담긴 표현으로 만든다 == 인코딩 단계
- 인코딩된 표현을 사용해 원본 입력을 재구성 == 디코딩 단계
- 학습 과정에서 오토인코더는 입력과 재구성된 출력 간의 차이를 최소화하도록 학습.

>  압축 전과 후의 결과가 비슷할수록 중요한 특징을 잘 표현한 것임. 즉 오토인코더를 사용하면 특징을 더 잘 학습 > factor!!!!

![image](https://github.com/hhzzzk/studyLog/assets/67236054/7bdc1bee-614e-43e1-9680-dbc4a65126d3)



선생님을 학습하고 패러프레이저로 특징을 추출하고 오토인코더를 통과시켜 factor = 특징을 잘학습한 걸 만든다.

학생도 특징을 추출하고 트랜스레이터로 *팩터 간 차이를 줄인다.*

![image](https://github.com/hhzzzk/studyLog/assets/67236054/001cf07b-0ffa-4303-ae8b-b6a0089a3b84)



식은 학생 네트워크의 손실함수 L 정의

해당 손실함수는 분류 손실 cls와 팩터 트랜스레이터 손실 ft로 구성된다.

![image](https://github.com/hhzzzk/studyLog/assets/67236054/92d1ae87-a522-4713-a6bd-95fcb219bd5b)



- FT

![image](https://github.com/hhzzzk/studyLog/assets/67236054/79a98d4d-35b9-4542-915e-656ce8e616ec)



## Position based Scaled Gradients (PSG) for Quantization

양자화를 위한 위치 기반 스케일드 그래디언트 기법이다. 모델의 가중치 양자화를 개선하기 위해 제안되었다.

1. 양자화 : 양자화는 가중치나 활성화 값을 더 적은 비트로 표현한다. 모델을 경량화하고 메모리 사용량을 줄인다.
2. 기존 양자화의 문제 : 기존 양자화는 가중치의 그래디언트를 이용해 양자화 파라미터를 업데이트 한다.
   - 그러나 이러한 방법은 모든 가중치에 동일한 양자화 파라미터를 적용해 모델의 복잡도에 따라 양자화의 효과가 감소할 수 있다.
3. PSG는 위치 정보를 이용해 각 가중치에 대해 다른 양자화 파라미터를 적용한다.
   - 모델의 특정 위치에서의 그래디언트가 큰 경우, 해당 위치의 파라미터를 크게 조절해 민감한 부분을 높은 비트로 표현한다.
   - 즉 PSG는 그래디언트의 크기를 기반으로 위치별로 양자화 스케일을 조절해 모델의 중요한 부분에 더 많은 비트를 할당한다.

**장점**

- 모델의 중요한 부분에 더 많은 비트를 할당 > 양자화 효과 UP
- 모델의 중요한 부분은 그래디언트가 크게 나타나는 곳이다.

보통 모델 학습 중 양자화 파라미터를 업데이트할 때 적용한다. PSG를 사용하면 모델의 양자화 성능을 개선할 수 있다.



## PSGD (Position-based Scaled Gradients Descent)

![image](https://github.com/hhzzzk/studyLog/assets/67236054/6f7bd326-455f-45a5-9fb4-89fd500a2146)

---

PSGD는 SGD, 경사하강법과 유사하다. SGD에 대한 변형으로 PSG를 적용한 것이다. 위치 기반 스케일드 처리를 한 그래디언트를 사용해 가중치를 업데이트한다.

FP는 Full Precision으로 전체 정밀도에서 먼저 모델을 사전 훈련한다. 즉 원본 데이터에 대해 모든 가중치를 고정된 정밀도 사용한다.

LP는 낮은 정밀도에서 추가적인 훈련을 한다.

*요약*

- 초기에는 전체 정밀도 FP에서 훈련을 진행하고 PSGD를 사용해 초기 훈련 단계에서 양자화에 적합한 분포를 형성한다.
- 그 후 낮은 정밀도 LP에서 추가적인 훈련과 양자화 관련 훈련(PTQ나 QAT)으로 최적화를 수행한다.
  - 모델을 압축하면서도 일정 수준의 정확성을 유지하려는 목적

---

**PTQ** (Post-training Quantization)

모델이 이미 훈련된 후에 양자화를 적용한다.

- PTQ는 훈련된 모델을 배포/실행하기 전에 양자화를 추가하여 모델 크기를 줄이고 속도를 높인다.

**QAT** (Quantization-aware Training)

모델을 훈련하는 동안 양자화를 고려한다.

- 훈련 중에 모델은 낮은 정밀도로 양자화될 것을 고려하여 가중치 및 활성화 함수의 동작을 조정하도록 학습한다.
- 훈련 중 양자화에 대한 고려 때문에 모델은 낮은 정밀도에서도 성능을 유지하려고 노력=양자화된 모델이 훈련 초기부터 더 효과적이다.
- 양자화에 대한 민감성을 줄인다.
  - **QAT는 최종 성능을 FP에서 학습하고 난 후에 양자화된 데이터를 활용하여 모델을 더 학습!!!!!!!!**
  - 양자화 관련 훈련 이후, 모델은 일반적으로 FP 데이터에 대해 미세 조정(fine-tuning)



## 모델 훈련에서 그래디언트 양자화 그리드 포인트로부터의 거리에 따라 조절하기

Scaling gradients based on the distance from the nearest grid point



![image](https://github.com/hhzzzk/studyLog/assets/67236054/2475245f-ceb5-4e10-acd8-0b104a0c6324)

그리드 포인트가 노란 점이다.

점에서 멀면?		그래디언트를 증가

- 높은 정밀도가 필요, 양자화에 대한 민감성이 낮으므로 더 큰 그래디언트를 사용해 빠르게 수렴하도록 한다.

점에서 가까우면 ?    그래디언트 감소

- 포인트랑 가까우면 높은 정밀도이므로 유지하자. 그러므로 해당 위치의 그래디언트를 크게 감소시켜 미세한 조정만 하도록 하자.

> 노랑점과 가까우면 양자화가 이미 잘되어있다. 그래디언트 줄여 덜 움직이게 하고
>
> 멀면 양자화가 잘 안되어 있으므로 그래디언트를 크게 해서 다음 업데이트에서 많이 움직이도록 한다.





## 양자화 훈련 중 그래디언트 스케일링 공식

![image](https://github.com/hhzzzk/studyLog/assets/67236054/0114921d-96b2-4faa-898e-ce67889becf4)

$s(x)=|x-\bar{x}(x)|+\epsilon$.

에서 x-x바의 절대값은 거리의 차이이다. 즉 노란 점=포인트와 값과의 거리차이.

거리가 작을수록 함수값이 작아지므로 



거리차이가 만약 0==노란점이면 그래디언트 0을 곱해서 업뎃하지 않는다.

아래 식이 그래디언트 업데이트 공식. 학습률에 거리차이를 곱하고 미분, 그래디언트 곱해서 업데이트함





## 실험결과

![image](https://github.com/hhzzzk/studyLog/assets/67236054/c8883a27-22d8-4e1d-8dd1-a2984b03c4bc)



PSGD가 더 좋은 성능을 보인다. LP에서 미세조정, 파인튜닝까지 되어서 약간 짜잘한 것들도 다 처리된 양자화된?

![img](https://velog.velcdn.com/images/3eung_h10n/post/5937501d-aa11-4aa6-aa12-530df06e3c5a/image.png)

- 양자화 할때 여러 값을 0으로 만든것인데 그럼에도 성능이 나온다면 pruning효과까지 얻은것
  - 양자화는 가중치를 더 작은 비트 수로 표현하는데 이 때 0이 많이 만들어지면 Sparsity 희소성 나타남
  - 희소성은 모델의 파라미터 중 일부가 0이 되는 현상 = 메모리 사용량 감소됨
- PSGD는 처음부터 양자화 후의 모습과 유사하게 학습하기 때문에 학습 완료 후 바로 양자화가 쉬움
  - PSGD는 타겟 비트로 가중치를 학습하므로, 타겟 비트로 양자화를 수행하면 성능이 잘 나옴



PSGD는 양자화 효과를 잘 살리면서도 학습을 수행하며, 양자화 후의 성능을 유지하는 데 도움을 줄 수 있습니다. **Pruning과 같은 희소성 효과도 동시에 얻을 수 있어** 효율적인 모델을 구축하는 데 기여할 수 있습니다.





![img](https://velog.velcdn.com/images/3eung_h10n/post/234b7cc1-464a-42ce-8a33-df879dd8218c/image.png)

- On-the-fly quantization(타겟 비트로 한번에 양자화)해도 성능이 잘 나옴

![img](https://velog.velcdn.com/images/3eung_h10n/post/4501414e-fa06-4649-ae19-bd2950bea66d/image.png)

- 처음 학습시 양자화에 친숙하게 학습하기 때문에 PTQ를 섞어써도 성능이 잘 나옴



## Prunning

![img](https://velog.velcdn.com/images/3eung_h10n/post/9f72eaed-9fe6-4ec2-8ffc-e21adb6025df/image.png)

**Unstructed pruning** : 필터 내부의 가중치 중에서 절대값이 작은 것들을 삭제한다.

**Structed pruning** : 여러개의 필터 중 일부를 통째로 제거한다.

- 프루닝은 종종 절대값이 작은 가중치나 필터를 삭제하는 방식. 이렇게 삭제된 부분은 훈련 중에 다시 채워지거나, 훈련 후에 fine-tuning을 통해 최적화된다.


- iterative한 프루닝은 여러 단계로 나눠 프루닝을 적용하며, 중간 중간 학습을 다시 수행하여 성능 손실을 최소화하는 효과



진도_13w2_11.29수(12p~38p)

## Relater work - Pruning

프루닝은 가지치기로 

![image](https://github.com/hhzzzk/studyLog/assets/67236054/c069aef1-4ed4-4f6c-b8a8-cbb81e18ff23)

- one-shot pruning은 모델 훈련 후 특성 희소성 sparsity로 모델을 단 한번만! 가지치는 것이다. 한번의 가지치기 작업으로 모델의 일부 파라미터를 제거한다.

ing

/

start

진도 14w1, 12.4.월 rec

32p 실험같은건 안봐도 된다

## DCIL(Decomposition of the Covariate-Induced Loss)

## DCIL - Dynamic pruning with feedback

43p 식 보기

![image](https://github.com/hhzzzk/studyLog/assets/67236054/37868f28-b96b-4ec1-b5a9-9324745f2c10)



approximation은 모델이 특정 가중치를 선택적으로 강제로 설정해 근사를 수행하는 것이다.

- 죽은 애들, 원래 0인 가중치들을 1로 강제하는 것이다.

> 마스크의 도함수를 계산할 때 비활성화된 가중치를 다시 활성화시키기 위해 도함수를 간단하게 1로 근사시켰다. 그러나 이럴 경우 안정성과 성능에 악영향 끼칠 수 있다.



가중치의 동적 가지치기, 다이나믹 프루닝을 사용해 모델을 효율적으로 훈련시키는 방법을 제시한다.

동적 가지치기는 모델의 특정 가중치를 **훈련 중에** 삭제하거나 비활성화해 모델 크기를 줄이고 계산 효율성을 향상시키는 기술이다.

![image](https://github.com/hhzzzk/studyLog/assets/67236054/bd4782f6-82b2-45f9-b88a-ef86b7bf020c)

원래의 가중치 Wi에 마스크를 적용한 것이 W바이다.

Mi는 해당 가중치의 마스크이다. 마스크가 1이면 가중치가 활성화, 0이면 비활성화된 상태이다.

w바에 대해 w, 기존 가중치로 미분을 하면 마스크가 된다. 왜냐면 w바는 m*w이므로...

![image](https://github.com/hhzzzk/studyLog/assets/67236054/250685ba-63ac-47ef-8639-140f579ceecb)

![image](https://github.com/hhzzzk/studyLog/assets/67236054/2d226983-4aa2-4bd4-84ba-1cde2a94f288)

-  w바를 w로 미분하면 m, 마스크가 된다. 즉 마스크는 w바의 도함수(w에 대한)이다.


> 결국 w바는 mw이므로 w바를 w로 미분하면 마스크다.
>
> 마스크를 1로 강제로 근사시킨다는 식이다.

![image](https://github.com/hhzzzk/studyLog/assets/67236054/71ce1120-0315-47f2-9c17-83977f764aae)

위처럼 강제 근사시키자 파란색 그래프 나온다.

성능이 아주그냥 요동치고 난리났다. >>>>>>다이나믹 프루닝 윗 피드백해서 DPF인듯!!!!!!!!!!!

대안 필요!!!!

## DCIL - Proposed method

DCIL(Decomposition of the Covariate-Induced Loss)

45p 이거 꼭 보셈 



함수 $\mathcal{F}^{\mathbf{W}}: \mathcal{X} \rightarrow \mathcal{Y}$는 입력 공간 $\mathcal{X}$에서 출력 공간 $\mathcal{Y}$로의 매핑을 의미하며, 이때 가중치로 $\mathbf{W}$가 사용됩니다.

손실 함수 $\mathcal{L}: \mathcal{Y} \rightarrow \mathbb{R}$는 출력 공간 $\mathcal{Y}$에서 실수로의 매핑을 나타냅니다.

---

DCIL(Decomposition of the Covariate-Induced Loss)의 업데이트 규칙은 다음과 같이 정의됩니다:

$\mathbf{W}$를 업데이트합니다. 학습률은 $\eta$이며, $\odot$는 요소별 곱셈을 나타냅니다.



업데이트에 사용되는 항목은 $\mathbf{M} \odot \nabla_{\overline{\mathbf{w}}} \mathcal{L} + (1 - \mathbf{M}) \odot \nabla_{\mathbf{W}} \mathcal{L}$입니다.

크게 2가지로 나누어볼 수 있다. M와 1-M!!!!!!!!

- 여기서 $\nabla_{\overline{\mathbf{w}}} \mathcal{L}$는 $\mathcal{L}$을 $\mathcal{F}{\overline{\mathbf{W}}}(\mathbf{X})$에 대해 미분한 값이고
- $\nabla_{\mathbf{W}} \mathcal{L}$는 $\mathcal{L}$을 $\mathcal{F}^{\mathbf{W}}(\mathbf{X})$에 대해 미분한 값입니다.

1. 마스크와는 손실함수를 w바로 미분한 것을 곱하고
2. 1-m과는 손실함수를 w로 미분한 것을 곱한다!!!!!

![image](https://github.com/hhzzzk/studyLog/assets/67236054/383c3dc4-9d1a-443e-bf87-e5055f2a8b47)



- $\mathbf{W}$는 모델의 가중치를 나타냅니다.
- $\eta$는 학습률을 나타냅니다.
- $\mathbf{M}$는 마스크 행렬로, 특정 가중치 업데이트에 대해 어떤 그래디언트를 사용할지 결정합니다.



이 방법은 가중치 업데이트를 두 부분으로 나누어 고려합니다. 

1. 첫 번째 부분은 입력 데이터의 특징에 대한 그래디언트 $\nabla_{\overline{\mathbf{w}}} \mathcal{L}$이며, 
2. 두 번째 부분은 전체 손실 함수에 대한 그래디언트 $\nabla_{\mathbf{W}} \mathcal{L}$입니다. 



이 두 부분은 마스크 행렬 $\mathbf{M}$을 사용하여 각각의 업데이트에 대한 중요도를 조절하며, 이는 모델이 특정 특징이나 측면에 민감하게 학습되도록 하는 데 도움을 줄 수 있습니다.



- M은 마스크 행렬이다. 마스크가 1이면 사는 애들, 0이면 해당 위치의 원소는 죽은 애들이다.

M=1일 경우

> 앞의 w바에 대한 그래디언트가 들어간다. w바의 그래디언트는 마스크, 즉 1이다. 
>
> 2번째 줄 식을 보면 결국 w바는 마스크를 씌운 후의 값, 그걸로 업데이트한다.

M=0일 경우

> w는 마스크를 씌우기 전의 값이다. m이 0이면 앞의 식은 사라지고 뒤의 식만 남아서
>
> 마스크를 씌우기 전의 값으로 업데이트한다.

- 위에서 M이 1인 산 애들이고 (1-M)이 0으로 죽은 애들이다. 즉 1-M에 근사가 수행된다.
  - 즉 원래 죽어야 하는 가중치들을 살리는 것이다.!
- $\overline{\mathbf{W}}$ 는 w에 대응하는 프루닝된 가중치들이다. ! 즉 M, 마스크가 곱해진 가중치이다.
  - 즉 w바는 프루닝된 가중치에 대한 업데이트를 의미한다. 마스크가 1이면 프루닝된 후의 w바를 업뎃

---

DCIL의 핵심은 프루닝된 가중치들을 다시 살리는 것이다.

​	프루닝은 모델의 가중치를 0으로 가지치기하는 기술인데

DCIL에서는 프루닝된 가중치인 $\overline{\mathbf{W}}$에 *마스크(M)를 곱해 가중치를 다시 살리는 업데이트를 한다.*

마스크에서 1로 설정된 위치는 사는 애들이고 0으로 설정된 위치는 죽은 애들이다.



---

46p

DPF랑 똑같아지려면? W가 W바가 되면 된다. 그럼 성능 안정적으로

- DPF는 모델의 동적인 가지치기 빈도를 조절해 모델의 성능을 개선한다.

51p 꼭 봐라, 45랑 51페이지만 봐도됨 다른거 보지마!!



![image](https://github.com/hhzzzk/studyLog/assets/67236054/efccd880-a12b-4acb-9d6b-3b101cd41b99)

업뎃이 출렁출렁 거리면 불안정한것.

성능이 안정적으로 된다 b 그래프

approximation을 최대한 빼면 좋다. 좋아진다.



```
시험범위 51p까지
수요일 휴강
객관식+주관식, 이캠퍼스 퀴즈 형태
주관식 푸는 문제 종이 필요
과정 필요없이 정답이 맞아야 할듯;; 7-8문제에서 객관식 더 추가 가능
주관식 3-4문제
```

end