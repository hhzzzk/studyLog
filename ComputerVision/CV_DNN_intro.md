# CV_DNN_intro



9w2

11/1

22p~?

## Loss function

손실함수 == 분류기의 성능이다.

분류기의 성능을 정량적으로 측정하는 지표다. 손실이 낮을수록 좋은 분류기이다. 

## Cross-Entropy Loss (Multinomial Logistic Regression)

분류문제에서 손실함수로 교차 엔트로피 함수, CE를 사용한다. 

다항 로지스틱 회귀는 여러 클래스로 분류하는 문제이다.

> Want to interpret raw classifier scores as probabilities

분류기의 출력은 보통 각 클래스에 대한 점수로 나타내진다. 이는 확률이 아니다. 이를 확률로 변환해 해석하도록 한다. 이를 위해 소프트맥스 함수가 사용된다. 소프트맥스 함수는 각 클래스의 점수를 확률로 변환한다. 확률이므로 모든 클래스의 확률 합은 1이 된다.

##👕 Softmax function

![image](https://github.com/hhzzzk/studyLog/assets/67236054/ff1e3908-fbe2-45f2-a9bf-41feafe35472)

위의 소프트맥스 함수는 다중 클래스 분류 문제에서 각 클래스에 대한 확률을 계산하는데 사용된다.

s는 각 클래스에 대한 점수이고

k는 주어진 데이터 포인트 xi에 대한 예측된 클래스를 나타낸다. 

W는 모델의 가중치이다.



주어진 입력 데이터 xi에 대해 클래스 k에 속할 조건부확률이 우측 공식이다. 

분모의 시그마는 모든 클래스 j에 대한 점수의 지수함수의 합이다. 이를 통해 점수를 확률로 변환한다.



## 👕 적용

![image](https://github.com/hhzzzk/studyLog/assets/67236054/325f60c6-66b0-4528-a7d9-41ca39fc6e90)

cat은 3.2

car은 5.1

frog는 -1.7

1. 세 개의 클래스에 exp를 취한다.
2. 클래스가 3개이므로 j는 3, exp 취한 세 개의 값의 sum을 분모로 해서 확률로 변환한다 == normalize
   - normalize가 확률로 변환한다. 즉 주어진 값들을 총합으로 나눠 상대적 비율을 유지하며 확률로 변환

## 👕 교차 엔트로피 손실

엔트로피는 확률 분포의 불확싱성을 측정하는 척도로 확률 분포가 얼마나 예측하기 어려운지를 나타낸다.



우측에서 교차 엔트로피 손실을 구하는 식이 Li로 

​	주어진 입력 x에 대한 클래스 y에 속하는 조건부 확률에 -log를 붙인다.



교차 엔트로피 손실은 모델의 예측과 실제 레이블 간의 차이를 측정한다. 즉 주어진 데이터에 대한 모델의 부정확성을 의미한다. 

이 값이 높을수록 모델의 예측이 실제와 다르다는 의미이다. 

## 👕 MLE

![image](https://github.com/hhzzzk/studyLog/assets/67236054/570fbfed-9e37-4dd2-a7c9-9a0c70ec8826)

MLE는 최대 가능도 추정, Maximum likelihood estimation은 주어진 데이터를 가장 잘 설명하는 모델 파라미터를 찾는 방법 중 하나이다.



소프트맥스로 구한 확률상 car이 0.87로 해당 데이터는 car에 속할 가능성이 87퍼센트이다.

frog의 확률이 0이기 때문에 frog 클래스일 확률은 거의 없다.



해당하는 교차 엔트로피 손실을 계산하면

1. cat: −log⁡(0.13)≈2.040−log(0.13)≈2.040
2. car: −log⁡(0.87)≈0.139−log(0.87)≈0.139

cat이 주어진 데이터에 더 부적합하다.