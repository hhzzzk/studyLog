# AI_2_확률 및 통계

- 기계학습이 처리할 데이터에 내재된 *불확실성*을 다룬다.



## 확률

- 확률 변수 : 사건에 다라 값이 결정되는 변수



## 분포

- 확률질량함수 : 이산 확률 변수의 분포
- 확률밀도함수 : 연속 확률 변수의 분포



## 확률 벡터

- 확률변수의 조합
- 결합분포 : 두 개 이상의 확률 변수를 *동시에* 고려한 확률 분포



## 확률 실험

주머니에서 번호를 뽑은 다음 번호에 따라 해당 병에서 공을 뽑고 색을 관찰한다.



## 조건부 확률

- 어떤 사건 A가 일어났다는 조건 하에 다른 사건 B가 일어날 확률



## 독립사건

- 두 사건 A와 B에서 한 사건의 결과가 다른 사건에 영향을 주지 않을 때 A와 B를 독립사건이라고 한다.

## 종속사건

- 두 사건 A와 B에서 한 사건의 결과가 다른 사건에 영향을 줄 때, A와 B를 종속사건이라고 한다.

![image](https://github.com/hhzzzk/studyLog/assets/67236054/d0a74a1c-951a-4663-83c2-988b0b424884)



5w2

10/4 수

```
오늘이나 내일 과제 나옴. 마감 8주차 월요일
중간고사 8주차 수요일 저녁..예상
```

## 리뷰

확률의 연쇄법칙, 체인룰은 언어모델의 언어패턴, 단어, 토큰들간의 결합확률을 이용한다.

31p

확률의 곱셈은 동시에 발생하는 것이고

덧셈은 count 서로 연관성이 없는 사건들의 확률을 더하는 것이다.



## 베이즈 정리

32p

확률에는 빈도확률과 베이지안 확률이 있다.

**빈도 확률** : 💚직접💚 실험 등으로 데이터를 얻는다.

**베이지안 확률** : 💚간접💚 실험하지 않아도 주어진 정보를 이용해 확률을 표현한다.

---

### 	💚베이즈 정리💚

일어나지 않았거나 불확실한 사건에 대한 *베이지안 확률을 구한다.*

![image](https://github.com/hhzzzk/studyLog/assets/67236054/1b4deda3-8b4c-45b0-8fe4-f0c2cef0535c)

**사후확률** : 직접 추정할 수 없다. 구하려는 목표. 결과B가 발생했다는 가정하에 원인A이 발생했을 확률

**우도확률** : 원인이 발생했다는 가정하에 결과가 발생할 확률

**사전확률** : 결과가 나타나기 전에 결정된 *원인의 확률*

**주변우도** : 사건B의 발현 확률



## 확률과 우도🌟

![image](https://github.com/hhzzzk/studyLog/assets/67236054/17c4d130-833a-45a8-b224-a662d493b4dd)

generative distribution : 주어진 데이터가 어떻게 생성되었을지를 나타내는 확률 분포이다.

확률은 어떤 사건이 발생할 가능성 또는 불확실성을 나타낸다. 특정한 조건에서의 확률을 계산할 수 있다.

우도는 주어진 데이터가 주어진 가설/모델에 대한 관계성/적합성을 나타낸다. 주어진 모델/가설 아래 관찰된 데이터가 나타날 확률이다.



## 베이즈 정리 증명

![image](https://github.com/hhzzzk/studyLog/assets/67236054/7b724489-f89d-4f19-866b-f1d8c9128d5b)

내가 실제로,카운팅해서 알아낸 확률 == 사전 확률로 사후확률을 구하겠다.



## 확률 실험에 베이즈 정리 적용

> 하얀 공이 나왔다. 어느 병에서 나왔는지 추정하라

실험설정 : 주머니에는 1,2,3 번호가 적힌 공들이 있다. 주머니에서 번호를 뽑고 해당 번호의 병에서 공을 뽑아 색을 관찰한다.

![image](https://github.com/hhzzzk/studyLog/assets/67236054/c82e5360-986a-4f23-a230-e61739ae6707)

---

하얀 공이 나오는 케이스는 1,2,3번 공을 뽑은 3가지다.

각 케이스의 확률을 계산하면 3가지의 사후 확률이 나온다.

그 중 가장 높은 확률을 찾는 것이다.



## 기계학습에 베이즈 정리 적용

![image](https://github.com/hhzzzk/studyLog/assets/67236054/20a7cac1-6433-4594-999b-487ba776c454)

이리스 꽃 데이터를 분류해보자.

꽃의 특징은 4차원으로 정리된다. 

각 케이스마다 사후확률을 추정한다. 그 중 가장 그럴듯한 케이스를 선택한다.



## 최대 우도 추정 MLE

확률 분포의 모수 θ를 추정한다. 가장 가능성 높은 == 우도가 최대가 되는 모수 값을 찾는다.

### 	💚우도💚

 주어진 모수 값에 대한 데이터(원인)이 발생할 확률이다.

L(θ|X)는 데이터 X가 주어진 상황에서 모수 θ일 때 일어날 가능성

### 	💚로그 우도💚

로그를 취해 계산을 편리하게 한다. 로그 우도는 우도를 자연 로그 취한 것으로 곱셈 연산이 덧셈 연산으로 변환되어 계산이 용이해진다.

```
1. 주어진 데이터셋 X에 대한 로그 우도 함수 L(θ|X)를 정의한다.
2. 로그 우도 함수를 최대화하는 모수 θ를 찾는다.
```

![image](https://github.com/hhzzzk/studyLog/assets/67236054/2d4e885f-4d9b-46de-ba08-643d1822d865)

## 통계적 대표값

발현된 데이터의 특성을 이해할 수 있는 대표값을 취하자

평균, 분산, 평균벡터, 공분산 행렬, 중앙값, 최빈값 등이 있다.



## 평균 벡터와 공분산 행렬 예

이리스 데이터베이스의 샘플 중 8개만 가지고 공분산 행렬을 계산한다.

먼저 평균벡터를 구한다. 첫번째 샘플에 적용한다.

나머지 샘플에도 같은 계산을 하고 결과를 모두 더한 다음 8로 나누면 공분산 행렬을 얻을 수 있다.



### 	💚공분산 행렬 구하기💚

각 변수의 평균을 구한다. 각 데이터 샘플에서 평균을 뺀다. (편차)

이를 이용해 각 공분산을 계산한다. 공분산은 편차 곱의 평균이다.

이를 모으면 공분산 행렬을 얻을 수 있다.

---

![image](https://github.com/hhzzzk/studyLog/assets/67236054/a801ba95-524c-4e5f-b568-e77a56f46cd4)

직접 구해보기

### 	💚공분산 행렬의 의미💚

공분산 행렬은 다변수 데이터의 공분산을 나타내는 행렬이다.

이 행렬은 데이터의 *차원 간 상관 관계와 분산을 함께 보여주는 지표*이다.

- 공분산 행렬은 차원축에 얼마나 퍼져있는지를 나타낸다. **데이터가 공간에 퍼진 정도이다.**

- 가장 잘 퍼진 고유벡터 차원축을 찾아서 저차원에 투영하면 그게 PCA이다.

  ### 💚공분산 행렬과 PCA💚

주성분 분석이라고도 한다. 데이터의 정보를 보존하면서 차원을 줄인다.

```
1. 데이터 중심화 : 데이터의 평균을 0으로 맞추기 위해 데이터 포인트에서 평균을 뺀다.
2. 공분산 행렬 계산 : 이 행렬은 데이터의 차원간 상관관계를 나타낸다.
3. 고유값 분해 : 공분산 행렬을 고유값과 고유벡터로 분해한다. 고유벡터는 데이터의 주성분 방향을 나타내며 고유값은 해당 방향의 중요성을 나타낸다.
4. 고유값을 기준으로 고유벡터 선택 : 고유값을 크기 순으로 정렬하고 주성분으로 사용할 고유벡터 선택. 주로 가장 큰 고유값에 해당하는 고유벡터를 선택한다.
5. 선택한 고유벡터/주성분을 사용해 데이터의 차원을 줄어들게 투영한다.
```

**PCA는 공분산행렬로 가장 잘 퍼진 고유벡터 차원축을 찾아서 저차원에 투영한다.** 

​	공분산행렬에서 가장 잘 퍼진 차원축은 해당 데이터를 가장 잘 나타내는 주성분이다.





## 확률 분포 유형

![image](https://github.com/hhzzzk/studyLog/assets/67236054/f17cc080-64dd-4922-bfc2-fa2894cd0ea0)

###	💙가우시안 분포💙

- 대칭성을 가진다. 평균을 중심으로 좌우대칭인 종 모양의 분포이다.
- 두 개의 매개변수로 정의된다. 평균과 분산/표준편차. 
  - 평균은 분포의 중심을 나타내고 분산은 데이터가 퍼져있는 정도를 나타낸다. 
  - 분산이 작을수록 데이터가 평균쪽에 집중되어있고 분산이 클수록 데이터가 분산되어있다.

---

![image](https://github.com/hhzzzk/studyLog/assets/67236054/c06a6ca0-d6a0-424c-9f7b-085dea7d8d27)

```
- x는 다변수 확률 변수 벡터,
- μ는 평균 벡터,
- Σ는 공분산 행렬,
- n은 변수의 개수,
- ∣Σ∣ 는 공분산 행렬의 행렬식(determinant)
```



### 	💙그 밖의 확률 분포 유형💙

**베르누이 분포** : 동전던지기. 성공과 실패 확률

**이항분포** : 동전 여러 번 던지기. 성공 확률이 p인 베르누이 실험을 k번 수행할 때 성공할 횟수의 확률 부노

**푸아송 분포** : 단위 시간 안에 어떤 사건이 몇 번 발생할지 표현하는 이산확률분포이다.



### 	💙혼합분포💙

둘 이상의 다른 확률 분포를 결합해 하나의 확률 분포를 만드는 확률 분포 모델이다.

각 구성 요소에는 *가중치가 할당되며 이는 해당 구성 요소 분포의 상대적인 중요성*을 나타낸다.

---

![image](https://github.com/hhzzzk/studyLog/assets/67236054/4c0f4cfc-45bc-4cf9-8a9b-ee4b58405c79)

+EM알고리즘

​	확률 분포의 모수를 추정하는데 주로 활용된다. 

​	E-Step과 M-Step을 반복해 모수를 최적화해 모수를 더 잘 추정하도록 한다.

​	Expectation : 주어진 모수 추정치를 기반으로 숨겨진 변수의 확률 분포 추정. 숨겨진 변수에 대한 예상값 계산

​	Maximization : 위에서 계산한 숨겨진 변수의 예상값을 사용해 모수를 업데이트. 

​				주어진 데이터 가장 잘 설명하는 모수 값 찾는다.

​	가우시안 혼합모델이나 클러스터링할 때 사용된다.



## 확률 변수 변환

- 기존 확률변수를 새로운 확률 변수로 바꾼다.
- 관계식을 이용해 새로운 확률 변수로 바꿀 수 있다.
  - 신경망 및 기계학습에서 관계식을 근사할 때 쓴다.



43p 확통끝

