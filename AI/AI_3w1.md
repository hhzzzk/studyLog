# AI_3W1

## 목적함수

- 성능, 오차, 비용 함수라고도 함
- JΘ  혹은 LΘ



함수의 의미는 입력과 출력의 상관관계

목적함수에서는 모델의 가중치, 파라미터인 세타값이 입력값으로 들어간다.

그리고 예측값을 y^이라고 함

실제 정답값은 y값이다.

오차는 y^-y의 차이이다. 

y는 정해진 값이므로 고정돼있다.

예측값 y^와 입력값은 변경가능하다. 

즉 W/Θ >>> Y^ >>> JΘ/Jw  의 함수 관계가 성립한다.

입력에 따라 목적 함수의 값이 변하므로 손실 __함수__라고 표현한다.



- 손실함수는 정량적 성능 판단 지표이다. 학습이 진행될수록 오차의 값인 손실함수의 값은 줄어들어야 한다.



*평균 제곱 오차 (MSE)*

손실 함수의 예시이다. FΘ(Xi)는 예측출력, 위에서 말한 Y^, 예측값이다.

Y는 정해진 정답값이다. 예측함수가 맞추어야 하는 실제 목표치이다.



## 기계학습을 통해 훈련 데이터 집합을 근사화함

y=wx + b > 2개의 학습 매개변수, w,b



## 훈련 training 과정

기계학습은 가장 정확하게 예측할 수 있는 최적의 매개변수를 찾는 작업이다.

처음에는 임의의 값에서 시작해 점점 예측 성능을 개선해 최적의 매개변수에 도달한다.

(== w값을 최적화해 손실함수의 값을 최소로 줄인다.)

![image](https://github.com/hhzzzk/studyLog/assets/67236054/265f6a3d-8820-4f45-869f-4179501957af)

그림의 경우 f3에서 완벽하게 근사한다. 다음단계인 추론으로 넘어간다.



## 추론 inference 과정

새로운 특징에 대응되는 목표치 예측, 

새로운 데이터를 넣어서 확인.

일반화된 성능을 확인하는 과정이다.



41페이지 처음에 임의의 매개변수 (0.1, 4.0)에서 시작해 손실함수를 줄여나가

3번째 시동세서 최적값을 찾았다.





## 학습 알고리즘

learning algorithm

- 최적의 매개변수를 찾는 행위
- 매개변수의 변화를 반복해 최소의 목적함수를 만족하는 최적의 해를 찾아가는 수치적 방법(최적화)
- JΘ를 줄이는게 목표이다.

![image](https://github.com/hhzzzk/studyLog/assets/67236054/b5dec37d-c3e4-4643-9ac9-1f8cea9b89cf)

min (JΘ)는 최소의 손실함수를 찾는 것이고 arg는 세타를 최적화시키는 값을 찾자는 의미이다.

![image](https://github.com/hhzzzk/studyLog/assets/67236054/661b942a-887d-43ed-bf58-e8d1176d7522)

4줄에서 방향, 미분을 사용한다. 그 이유는?



> 오목/볼록 함수, convex는 최소/최대값이 1개이다. 즉 convex를 증명하면 최소/최대값이 1개인게 보장된다.
>
> 미분은 순간변화량을 의미하는데
>
> 세타 >>> 예측값 Y^ >>>  JΘ
>
> 여기서 그럼 손실함수를 세타로 미분하면 양의 증가방향에 대해 미분한 것이다.
>
> 그러니 최종에서는 음수를 붙여야 한다....?



대충 44페이지까지 함