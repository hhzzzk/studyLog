# AI_5_Training_Art_for_Deep_Learning

# 목적함수

## MSE의 한계

MSE는 기계학습에서 일반적으로 사용되는 목적함수 중 하나로 모델의 예측값과 실제값 사이의 평균 제곱오차를 게산한다. 



몇 가지 허점이 존재한다. 그 중 하나느 벌점, 패널티 부여에 관한 것이다.

- 벌점은 모델이 예측에서 큰 오류를 범할 때 패널티를 부여해 모델이 더 나은 예측을 하도록 유도하는 역할



제시된 예제를 보면 오차가 오른쪽이 더 크다. 그러므로 단순히 생각하면 오른쪽에 더 패널티 부과해야 함



wx+b=시그모이드 함수와 도함수 그래프의 가로축이 커질수록 경사도가 작아지는 현상도 생김

경사 하강법의 특징 중 하나로 절대값이 너무 커질수록 기울기가 거의 0에 수렴함. 이로 인해 그래디언트 소실 문제 발생

여기서는 예제의 오차가 극에 달해서 기울기가 작아짐. 오류역전파하며 소실 문제 발생



## 교차 엔트로피

레이블label에  해당하는  𝑦가  확률변수  (부류가  2개라고  가정하면  𝑦∈{0,1}) 

- 확률  분포: 𝑃는  정답  레이블, 𝑄는  신경망  출력

o는 실제 클래스 0이나 1

Q(o)는 모델의 예측값

![image](https://github.com/hhzzzk/studyLog/assets/67236054/e9edd79e-97c5-468c-94f7-0be8a472cd3b)



## 음의 로그우드(Negative Log Likelihood, NLL)

모든 출력 노드값을 사용하는 mse나 교차 엔트로피와 달리 oy라는 하나의 노드만 적용한다

oy는 샘플의 레이블에 해당하는 노드의 출력값, 즉 예측값이다!!

잘못분류할수록 값이 크게 나온다.

작은 값이 나와야 맞게 분류한 것이다.



## 소프트맥스와  로그우도  궁합

- 소프트맥스는 최댓값이 아닌 값을 억제하여 0에 가깝게 만든다는 의도 
- 로그우도는 입력 샘플의 정답 부류에 해당하는 노드만 보겠다는 의도 
- 따라서, 둘을 결합하여 사용



## 예제

실제 클래스의 확률 분포 P가 다음과 같이 주어진다고 가정합니다:

P(0) = 1P(1) = 0P(2) = 0

모델의 예측 확률 분포 Q가 다음과 같이 주어진다고 가정합니다:

Q(0) = 0.13Q(1) = 0.87Q(2) = 0.00

**이제 교차 엔트로피를 계산할 수 있습니다:**

H(P, Q) = -Σ(P(i) * log2(Q(i)))

1. i = 0:H(P(0), Q(0)) = -(1 * log2(0.13)) = -(-2.0404) = 2.0404
2. i = 1:H(P(1), Q(1)) = -(0 * log2(0.87)) = -(0) = 0
3. i = 2:H(P(2), Q(2)) = -(0 * log2(0.00)) = 0 (주의: log(0)는 정의되지 않으므로 0으로 간주합니다.)

이제 각 클래스에 대한 교차 엔트로피를 계산했습니다. 결과는 다음과 같습니다:

H(P, Q) = 2.0404 (for i = 0)

H(P, Q) = 0 (for i = 1)

H(P, Q) = 0 (for i = 2)

따라서 주어진 확률 분포 P와 모델의 예측 확률 분포 Q에 대한 교차 엔트로피 값은 다음과 같습니다:

H(P, Q) = 2.0404 (for i = 0)

H(P, Q) = 0 (for i = 1)

H(P, Q) = 0 (for i = 2)



## 비교

교차엔트로피는 P x logQ해서 시그마로 다 더하고 앞에 음수붙인다. 정답값이 필요하다.



**로그우도는 출력값만 있으면 된다.**

!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!



## 소프트맥스와 힌지로스 출력 비교

소프트맥스는 다중 클래스 분류 문제에 주로 사용. 각 클래스에 대한 확률 출력, 더하면 1

소프트맥스 손실은 실제 클래스와의 차이 최소화하도록 학습한다.



힌지손실은 이진분류에서 주로 사용

모델의 출력값을 사용해 각 데이터포인트가 어느 클래스에 속하는지 결정하고 이를 1, -1로 한다.

힌지 손실은 제대로 분류했으면 손실이 0이고 잘못분류했으면 손실이 발생(0-inf)한다.

- 잘못 분류한 데이터에 대한 손실만 고려, 정답 정보를 무시
  - 이로 인해 데이터에 대해 둔감함!!!!!



# 성능 향상을 위한 기법

## 데이터 전처리

**규모 문제** : 데이터의 각 피처는 서로 다른 규모와 범위 가질 수 있다. 데이터 규모 조절하는 스케일링 필요

- 경사하강법은 경사도로 가중치를 업데이트하는데 서로 단위가 다른 특징들일 경우 학습 속도에 큰 차이가 발생한다.
- 스케일링을 통해 특징 값의 범위를 조절해 모든 특징이 비슷한 범위 내에 있도록 해야 한다.

**모든 입력이 양수**

- 해당 특징들의 가중치가 양수로 초기화되면 모든 가중치 증가, 음수면 반대
- 가중치가 모두 증가, 혹은 모두 감소하는 동일한 방향으로 업데이트되면 경로가 지그재그하게 된다. 속도 느려진다.
- 이를 해결하기 위해 학습률을 조절해 경사도를 분산시키거나 가중치를 정규화해야 한다.



## 데이터 정규화

데이터 정규화는 규모 문제와 양수문제를 해결한다!!!!!

- 특징별 독립적으로 정규화를 적용한다.

표준화는 특징의 평균을 0으로 표준편차를 1로 만드는 방법이다.

최대-최소 스케일링은 데이터를 [0,1] 또는 [-1,1] 범위로 변환한다.

- 데이터에서 최소값을 빼고 최대값으로 나눠 데이터를 변환한다. 데이터의 분포를 임의로 조절 가능



## 명목 변수 normal value를 원핫 코드로 변환 전처리

!! 범주형 데이터를 수치형 데이터로 변환

명목 변수는 객체간 서로 구분하기 위한 변수이다. 걍 문자열로 표현하는 그런

명목 변수는 거리 개념이 없다. 원핫 코드는 값의 개수만큼 비트를 부여한다.



성별은 남여만 있으므로 원핫으로 하면 두개의 비트를 사용해 1,0 또는 0,1을 써서 남녀를 구분한다.

체질은 4비트를 사용할 것이다.



이를 사용해 샘플을 전처리하면

- 키: 1.755m
- 몸무게: 65.5kg
- 혈압: 122
- 성별: 남자 → [1, 0]
- 체질: 소양인 → [0, 0, 1, 0]

> [1.755, 65.5, 122, 1, 0, 0, 0]





## 가중치 초기화

- 대칭적 가중치 문제 : 같은 레이어의 두 뉴런이 동일한 가중치 값을 가지는 경우, 중복되는 역할을 하므로 학습에 악영향
- 해결 : 가중치를 난수로 초기화한다. 이를 통해 대칭 파괴 symmetry break
  - 가우시안 또는 균일 uniform 분포에서 난수를 추출한다. 두 분포는 성능 차이 거의 없음
  - 난수 범위가 중요하다.
    - 일반적으로는 [-r, r] 사이에서 난수를 발생시킵니다. 이때 r은 초기화 방법에 따라 다르게 결정됩니다.
    - Xavier 초기화: r은 1 / √𝑛in 으로 설정하며, 𝑛은 이전 층의 뉴런 개수입니다.
    - r은 √(6 / 𝑛in + 𝑛out) 으로 설정하며, 𝑛은 이전 층의 뉴런 개수와 나가는 뉴런 개수를 더함
  - 편향은 보통 0으로 초기화한다.
    - 알렉스넷은 평균0, 표준편차 0.01인 가우시안에서 난수 생성
    - 레저넷은 평균0, 표준편차 루트 2/ 𝑛in 가우시안에서 난수 생성, 편향0



초기화가  너무  작으면, 모든  활성  값  영이  됨, 경사도도  역시  영 

- 학습  저하

초기화가  너무  크면, 활성  값  포화, 경사도는  영 

- 학습  저하

초기화가  적당하면,모든  층에서  활성  값의  분포가  좋음 

- 적절한  학습  수행



## 활성함수

## ReLU

 경사도  포화gradient saturation 문제  해소



## ReLU의  변형

+ Leaky ReLU (보통  𝛼  =  0.01을  사용)


+ Parametric ReLU (𝛼 를  학습으로  알아냄)

최근의 활성함수들은 다음 문제를 해결하려 한다.

1. 포화된 영역에서 경사도 소실 문제 - 렐루 등 해결
2. 출력값이 0 중심 문제 - 렐루 등은 출력값이 영 중심 가짐
3. 연산량 문제



## 공변량 변화 covariate shift

훈련 데이터 집합과 시험 데이터 집합의 분포가 다른 경우 나타난다.

이로 인해 모델이 훈련 데이터로부터 학습한 특징을 시험 데이터에 적용할 때 문제 발생 가능



내부의 공변량 변화 - internal covariate shift는 신경망에서 발생하는 특별한 형태의 공변량 변화

- 딥러닝 신경망에서 여러 레이어에서 입력의 출력이 변환되면서 데이터 분포가 계속 변화
- 레이어가 깊어질수록 공변량 변화가 더 커진다. 학습을 방해



해결하려면 배치 정규화나 드롭아웃, 레지듀얼 연결 등

## 공변량 변화 해결

## 배치 정규화 batch normalization

공변량 시프트 현상을 완화하기 위해 신경망의 각 층에 정규화를 적용한다.

- 정규화 적용 위치가 중요하다!!!! 주로 해당 레이어의 활성화함수(비선형함수) 적용 전에 이뤄짐
  - 보통 FC나 CONV 다음에 적용, 즉 활성화 함수 적용 전에 정규화 수행해 레이어의 입력 분포 안정화시키기
  - 입력과 중간결과 중 중간 결과에 적용하는 것이 유리하다
- 훈련집합 전체보다 미니배치에 적용하는 것이 유리하다
  - 배치 정규화는 미니배치에 대해 적용

## 정규화 변환 수행 코드

1. 미니배치 단위로 평균, 분산을 구해 정규화하고
2. 비례와 이동을 적용한다. 세부 조정
   - 𝛾와  𝛽 는  노드마다  고유한  매개변수로서  학습으로  알아냄



배치  정규화  장점

- 신경망의  경사도  흐름  개선 
- 높은  학습률  허용
- 초기화에  대한  의존성  감소
- 의도하지  않았지만  규제와  유사한  행동을  하며, 드롭아웃의  필요성을  감소시킴



# 확률적 경사하강법 변형

## 경사 하강법을 통한 매개변수 탐색 및 최적화 문제

1. 지역 최적화 문제
   - 최적화 문제에서 함수의 목적은 손실함수를 최적화하는 것이데. 이 때 손실함수는 여러 최소값을 가질 수 있다.
   - 그 중 지역 최소값을 가질수 있다. 전체 최소값을 구해야 하는데
2. 안장점
   - 안장점은 경사가 0이지만 극소값이나 최대값이 아닌 지점이다. 안장점에서 경사하강법은 움직이지 않고 수렴한다.
3. 잡음 현상
   - 훈련 데이터 집합의 일부를 사용해 매개변수의 기울기를 추정한다. 이 때 경사도에 노이즈가 포함될 수 있어 업데이트가 불안정해질 수 있다.

해결!!!!!!!!!!!!!!!!

- 모멘텀=관성
  - 모멘텀은 현재의 업데이트 방향뿐 아니라 이전 업데이트 방향을 고려해 매개변술르 업데잍트
  - 과거에 이동한 방식을 기억하며 현재의 방향으로 일정 이상 추가 이동한다.
    - 이를 통해 잡음에 강한 관성을 부여하고 지역 최소값이나 안장점에 빠지는 문제 완화
  - 수렴 속도 향상, 지역 최소값 쉽게 빠져나옴

## 관성을 적용한 SGD 가중치 갱신 수식

V는 이전 경사도를 누적한 것이다.

알파의 효과=관성의 정도

- 알파-0이면 관성이 적용안됨.
- 1에 가까울수록 이전 경사도 정보에 큰 가중치를 준다. V에 가중치를 준다. > 그리는 궤적이 매끄로워진다
- 보통  0.5, 0.9, 또는  0.99 사용  (또는  0.5로  시작하여  세대epoch가  지남에  따라  점점  키워  0.99에  도달하는  방법)



관성의 효과로

지나침 overshooting 현상을 누그러뜨린다



네스테로프 가속 경사도는 예견한 곳의 경사도 사용 = 멈춤 용이



## 적응적 학습률 기반의 확률적 경사 하강법

적응적 학습률은 학습 과정에서 각 매개변수에 대한 학습률을 개별적으로 조절해 효율적인 학습을 돕는다.

일반적인 경사 하강법에서는 모든 매개변수에 대해 동일한 학습률을 사용, 이로 인해 너무 큰 학습률로 인한 발산 오버슈팅이나 너무 작은 학습률로 인한 수렴 지연 발생 가능



적응적 학습률 방법

1. 매개변수 별로 학습률 조절
2. 이전 경사도와 현재 경사도의 부호를 고려
3. 비슷한 방법으로 학습률 담금질 sa
   - sa는 초기에는 큰 학습률을 사용하고 학습이 진행됨에 따라 학습률을 감소시켜 점진적으로 수렴을 돕는다. 이는 전역 최적점에 빠르게 수렴, 지역 최소값에서 빠져나올 수 있게 한다.



RMSProp은  가중  이동  평균weight moving average 기법  적용





## 규제

명시적  규제와  암시적  규제

+ 명시적 규제: 가중치 감쇠나 드롭아웃처럼 목적함수나 기계학습 모델을 직접 수정하는 방식 
+ 암시적 규제: 조기 멈춤, 데이터 증대, 잡음 추가, 앙상블처럼 간접적으로 영향을 미치는 방식




---

진도_13w2_11.29수(65p~끝까지) + 6챕터 약간

55p 중요. 직접해보기

# 4 규제 : Dropout

드롭아웃은 신경망에서 사용되는 정규화(규제) 기법 중 하나로 오버피팅을 줄이는데 주로 사용된다.

![image](https://github.com/hhzzzk/studyLog/assets/67236054/7f6fac5d-5a25-4f17-85cd-a2b071db9014)



신경망의 일부 뉴런을 랜덤하게 선택해 제거한다.

1. 랜덤 뉴런 제거 : 각 뉴런을 제거할 확률 p는 보통 0.5이다. 확률에 따라 선택된 뉴런을 해당 단계에서 제거된다. 학습에 사용되지 않는다.
2. 부분 네트워크 학습 : 신경망의 랜덤 제거로 인해 새로운 구성의 *부분 신경망*이 각각 학습되는 효과가 생긴다.
3. 앙상블 효과 : 각 학습 단계에서 다양한 뉴런 부분집합에 대해 모델이 학습된다. 이는 앙상블 학습과 유사한 효과 > 모델의 일반화 능력 향상, 과적합 줄여준다.



드롭아웃은 보통 완전 연결층(fully connected layer)에 적용되지만 CNN이나 RNN 등의 신경망에도 적용될 수 있다. 드롭아웃을 통해 모델의 일반화 능력을 향상시키고 훈련 데이터 의존성을 줄일 수 있다.



## Dropout : mean activation, activation 비교

![image](https://github.com/hhzzzk/studyLog/assets/67236054/fd970ae1-a2f5-485b-a9fe-afffb89ed25e)

평균 활성화

- 드롭아웃 적용 전에는 모든 뉴런이 학습에 참여하므로 전반적인 활성화 수준이 높다.
- 드롭아웃 적용 후에는 일부 뉴런이 제거되므로 평균 활성화가 낮아진다.
  - 이는 모델이 각 학습 단계에서 일부 뉴런만 사용해 더 일반화 효과를 이끌어낸다.

활성화 분포

- 적용 전에는 전체 범위에 걸쳐 분포한다.
- 적용 후에는 일부 뉴런이 제거되어 더 sparse하고 부분적이다. 



##Dropout : 인공신경망의 완전연결층에 드롭아웃을 적용한 알고리즘

드롭아웃은 주로 training 훈련 단계에서 사용된다. 

- 훈련 단계에서는 일부 뉴런을 제거해 학습을 돕는다.

테스트 단계에서는 비활성화된다.

- 테스트 시에는 전체 네트워크를 사용해 예측을 수행해야 한다.



왜?

- 드롭아웃을 훈련과 테스트에서 모두 사용할 경우 모델이 더 적은 노드로 작동하게 되어 테스트의 성능은 향상될 것이다.
- 그러나 테스트와 훈련 환경에서의 모델 동작이 달라진다.
  - 드롭아웃을 적용할 경우 테스트 단계에서 사용되는 가중치의 기대값과 훈련 단계에서 사용된 가중치의 기대값이 다를 수 있다.
    - 이를 보정하기 위해 주로 테스트 단계에서 드롭아웃 비율을 고려해 훈련된 가중치를 조정한다.
    - 훈련시에는 드롭아웃 확률을 고려해 뉴런을 제거하고 테스트할 때는 해당 드롭아웃 비율을 곱해 가중치를 보정한다.
      - 이를 통해 훈련과 테스트 간에 일관성을 유지하며 모델 성능 평가가 가능하다.

---

![image](https://github.com/hhzzzk/studyLog/assets/67236054/9605909e-294c-4731-a3eb-278e02b876c7)

- 보통 드롭아웃은 입력층과 은닉층에 다른 드롭아웃 비율을 적용한다. 해당 비율은 각 노드의 드롭아웃, 제거될 확률이다.
  - 여기서는 Pinput = 0.2, Phidden = 0.5

![image](https://github.com/hhzzzk/studyLog/assets/67236054/d02e9ea7-fd7f-4e27-a72a-f3037df294db)

- 테스트 때는 모든 노드가 존재







# 5. 하이퍼 매개변수 설정

기계학습모델의 두 가지 매개변수

1. 내부 매개변수(가중치)
   - 모델의 학습과정에서 최적화되는 변수, 가중치라고도 한다.
   - 훈련 데이터 집합에 기반해 학습 알고리즘으로 갱신됨
2. 하이퍼 매개변수
   - 모델의 외부에서 주어지며 사람이 설정하는 값
   - 모델의 구조나 학습 동작 조절에 사용.
   - 대표적으로 은닉층의 개수, CNN의 필터 크기와 보폭, 학습률 등
   - 하이퍼 파라미터는 모델의 성능과 학습 특성에 큰 영향을 미친다.
3. 비교
   - 모델 내부에서 학습됨 VS 외부에서 사람이 결정
   - 경사하강법으로 최적화 VS 실험과 경험적으로 조정

![image](https://github.com/hhzzzk/studyLog/assets/67236054/c9f97b8d-7630-4c18-baf4-361c7f7273c9)

## 5 : 하이퍼 매개변수 선택

주로 표준 참고 연구가 제시하는 기본값을 참고한다. 여러 후보값 중 주어진 데이터에 가장 최적인 값을 선택한다. 이러한 과정을 하이퍼 매개변수 최적화라 한다.

5줄 valid set으로 성능을측정한다.

![image](https://github.com/hhzzzk/studyLog/assets/67236054/f35f793e-ff81-4c8d-a6b1-9f4c10ce6efd)

하이퍼 매개변수 최적화 방법 4가지

3줄(하이퍼 매개변수 조합 생성)을 구현하는 방법에 따라 수동 탐색, 격자 탐색, 임의 탐색이 있다.

- 최근에는 하이퍼 파라미터 최적화도 자동화시키는 방법들이 연구 중이다.



## 5 : 그리드 서치, 랜덤 서치 비교

![image](https://github.com/hhzzzk/studyLog/assets/67236054/1a3c7418-a707-4f6b-a6e4-e512ca14fdae)

격자 탐색(그리드 서치)

- 미리 정의된 하이퍼 파라미터 값들의 조합을 모두 시도한다. 모든 조합을 테스트하기 때문에 전체 탐색 공간을 탐색한다.
- 조합이 많은 경우 계산 비용이 높을 수 있다. 고차원의 조합 탐색에서 비효율적



임의 탐색(랜덤 서치)

- 난수를 사용해 조합을 생성한다. 특정 범위 내에서 랜덤으로 조합을 선택해 계산 비용이 낮다.
- 기계학습의 경우 하이퍼 파라미터가 m개이고 q개의 구간을 가진다면 q^m개의 점을 탐색해야 한다. 매우 큰 탐색공간이다. 랜덤 서치는 이런 공간에서도 효과적이다.



로그 공간

- 로그 공간을 사용해 간격을 조절할 수 있다. 로그 간격으로 탐색하는 것은 학습률 등의 하이퍼 파라미터에서 유리하다.
- 0.0001부터 1까지의 균일한 간격(uniform)으로 탐색할 경우 작은 값들의 영향력은 매우 작아 무시될 수 있다. 로그 공간에서의 간격(log-uniform)을 사용하면 작은 값이므로 2배씩 증가시켜 더 균형이 맞다

---

![image](https://github.com/hhzzzk/studyLog/assets/67236054/aef2f31f-488c-48b6-9ebd-4e00034af339)

uniform VS log-uniform

- 유니폼 분포는 특정 범위 내에서 모든 값이 균등하게 나타나는 분포이다.
- 로그 유니폼 분포는 로그 스케일에서 균일하게 나타나는 값들의 분포이다.
  - 작은 값에서는 큰 간격을, 큰 값에서는 작은 간격을 나타내 균형 있는 분포가 된다. 가변성을 추가!



> 그리드보다 랜덤 서치가 효율적
>
> 유니폼보다 로그유니폼이 더 효율적!



## 5 : 하이퍼 파라미터 탐색 전략

coarse-fine 탐색 전략은 초기에는 크게크게 넓은 범위를 빠르게 탐색하고, 그 후에는 fine하게 세밀하게 탐색하는 전략이다.

그림에서 검정 점으로 coarse하게 탐색하고 빨간 범위를 fine하게 탐색

![image](https://github.com/hhzzzk/studyLog/assets/67236054/1d1c055f-0f30-4652-ab31-f11f5be5af69)



하이퍼 파라미터 선택의 5단계

1. check initial loss
   - 초기손실을 확인한다. weight decay 가중치 감소를 비활성화하고 초기화 단계의 loss을 확인한다. 즉 가중치 감쇠가 없을 때의 모델 초기 손실을 확인한다.
   - 초기 손실은 모델이 아직 어떤 데이터에도 적응되지 않은 상태의 손실이다.
2. overfit a small sample
   - 모델을 작은 훈련 데이터 샘플에 대해 오버피팅시킨다. 100프로의 훈련 정확도를 달성시킨다.
   - loss가 줄어들지 않는다면 LR(학습률)이 너무 낮거나 초기화가 잘못되었을 수 있다. 반대로 loss가 무한대로 증가하거나 NaN으로 발산하면 LR이 너무 높거나 초기화가 잘못된 것이다.
3. find LR that makes loss go down
   - 이전 단계에서 사용한 아키텍처를 사용하고 모든 훈련 데이터를 사용한다. 작은 weight decay를 적용, 100번의 반복 내에서 loss가 감소하는 LR을 찾는다.
4. coarse grid, train for 1-5 epochs
   - 3단계에서 작동한 몇 개의 LR과 weight decay를 선택해 각각에 대해 모델을 훈련시킨다.
5. refine grid, train longer
   - 4단계에서 가장 좋은 모델을 선택해 오래 훈련시킨다.
6. look at loss and accuracy curves
   - loss가 어떻게 떨어지는지. 빨리 떨어지는지 느린지 등 경향성을 확인해 조정방법을 선택한다. (coarse/fine)





## 5 : 인공신경망의 학습 전략

신경망의 훈련은 iterative, 반복적인 과정

1. setup
   - 데이터 전처리, 가중치 초기화, 규제/정규화
2. monitor training dynamics
   - 훈련 도중 데이터 분포의 변화 및 정규화를 모니터링한다.
   - 최적화 알고리즘으로 모델 매개변수를 업데이트
   - 하이퍼 파라미터 튜닝
3. evaluate and improve
   - 모델 앙상블, 훈련 데이터를 증강하거나 전이학습 등으로 성능을 향상, 디버깅으로 문제 해결 및 모델 안정성 향상

이러한 과정으로 신경망 모델을 반복적으로 훈련하고 최적화해 성능을 높이고 일반화 능력을 향상시킨다.

![image](https://github.com/hhzzzk/studyLog/assets/67236054/e7bb5fe0-a820-4c0d-867b-d2da226f884e)





# 6. 2차 미분 정보 기반의 매개변수 최적화 기법

## 6 : 뉴턴 방법

지금까지 주로 배웠던 경사 하강법은 1차 미분을 사용했다.

1차 미분의 한계는 방향만 알 수 있고 얼마나 이동해야 하는지 크기 정보는 모른다.

이를 개선하는 방법에 2차 미분 정보를 활용하는 방법이 있다.

![image](https://github.com/hhzzzk/studyLog/assets/67236054/cd04113a-87b9-4684-a5a8-7088d0614411)

- 뉴턴 방법은 2차 미분 정보를 활용해 경사하강법보다 더 빠른 경로를 알아낸다. == 빠르게 최적화 가능
  - 그러나 헤시안 행렬을 계산하는 과정이 추가된다. 계산 비용이 추가된다.



## 6 : 1차 미분 최적화와 2차 미분 최적화 비교

![image](https://github.com/hhzzzk/studyLog/assets/67236054/75d91157-a445-4426-87eb-3051be4ad3cf)

2차 미분으로 오목, 볼록함수 판별이 가능하다.

점에 접하는 부분을 통해 포물선으로 근사 가능하다. 



## 6 : 뉴턴 방법 정의

뉴턴 방법은 테일러 급수를 이용해 함수의 근사치를 찾는 최적화 알고리즘이다. 여기서는 2차 미분 값이 필요하므로 2차까지의 도함수 정보만을 사용한다.

1. 테일러 급수 적용

   - 테일러 급수는 특정점의 미분계수를 계수로 가지는 다항식의 극한

   ![image](https://github.com/hhzzzk/studyLog/assets/67236054/6e84a7e4-5678-4b34-814b-2556df9dda29)

   - (𝑤  + 𝛿)에서 𝛿는 미소한 량, 매우 작은 양을 의미한다. 

2. 매개변수를 복수로 확장하면 헤시언 행렬이 된다.

   - 헤시언 행렬은 2차 도함수의 정보를 가지고 있다.

   ![image](https://github.com/hhzzzk/studyLog/assets/67236054/44f1156e-0e32-4d38-803c-9404e4f6f7a8)

3. 𝛿으로 미분한다.

   ![image](https://github.com/hhzzzk/studyLog/assets/67236054/ed77c2ff-13d4-4519-ac2a-4f5833f75464)

   ​

   (𝑤  + 𝛿)가 최소점이라면 해당 위치의 1차 도함수는 0이 된다.

   즉 3번에서 미분한 값이 0이 되는 지점을 찾아낸다.

   ![image](https://github.com/hhzzzk/studyLog/assets/67236054/7cf383eb-b2af-454a-bffb-131f76695a91)

정리하면 위의 헤시안 역행렬과 그래디언트의 곱으로 나타낼 수 있다.



77p 시험 나올 수도. 직접해보기

![image](https://github.com/hhzzzk/studyLog/assets/67236054/cae69a8a-7d51-4024-b7f9-f7f98489e0d5)

## 6 : 뉴턴 방법의 한계

헤시안 행렬의 역행렬을 구하려면 time complexity가 O(m^3)인 매우 큰 연산량이 필요하다.

그래서 유사 뉴턴 방법을 사용한다.



## 6 : 유사 뉴턴 방법

직접적으로 헤시안을 찾는게 아니라 반복을 통해 근사를 찾는다.

- L-BFGS를 많이 사용. 