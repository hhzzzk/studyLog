# OS_7w_22-2, 22-3

[TOC]

## 22-2 Beyond Physical Memory: Belady's Anomaly(1/4)

https://www.youtube.com/watch?v=ANyaanTkLNA&list=PLGgVuvaPty_16DKVq72S3ZeyJ2GaAxsE5



```markdown
(((Belady's Anomaly : 여담
벨러디 아저씨가 OPT 만듦. 일반적으로 캐시의 크기가 커지면 히트율이 증가하는데
FIFO는 더 안좋아짐. 이걸 벨러디의 Anomaly라고 함
LRU와 같은 다른 정책들은 히트율 좋아짐. 왜냐면 스택특성 stack propery라는 특성가져서임
캐시 크기가 n+1 로 증가하면 캐시크기 n 일때의 내용을 포함함. 그래서 캐시 크기 증가하면 히트율은 최소 유지됨. FIFO와 랜덤은 스택 특성을 가지지 않음!)))
```

여담이 아니었다ㅋㅋ..

결론

> stack property는 캐시 사이즈가 n에서 n+1로 증가하면 hit 확률이 증가하는데(최소유지, LRU, OPT)
>
> 예외적으로 FIFO는 stack propery를 만족할 때도 있고 아닐 때도 있어서 전체적으로 hit 확률감소



## 22-2 Beyond Physical Memory: Workload(2/4)



```markdown
# 22.6 워크로드에 따른 성능 비교

# No-locality Workload
- 접근되는 페이지들의 집합에서 페이지가 랜덤으로 참조됨
- 예제는 프로세스의 가상메모리에 100개의 페이지가 있음. 페이지들이 총 10000번 접근됨
>>> LRU, FIFO, 랜덤 모두 동일 성능, 히트율은 캐시의 크기와 비례
	캐시가 충분히 커서 모든 워크로드를 포함할 수 있으면 어떤 정책이든 상관없이 히트율100프로
	OPT가 매우 좋은 성능 보임
	

# 80-20 Workload
- 20프로의 페이지에 80프로의 엑세스가 몰림, 인기페이지
>>> OPT > LRU > FIFO,랜덤

(((그렇다면 랜덤과 FIFO를 개선한 LRU 정책이 역시 베스트인가?
그렇지는 않다. 미스로 인한 영향(가격이 비싸다던가 시간소요가 크다던가)이 크지 않다면
LRU의 장점이 다소 약화됨)))

# The Looping Workload
- 1-X개의 페이지들을 순차적으로 참조함
- X번째 페이지부터 다시 1,2,3...X 반복 참조함
>>> OPT > 랜덤 > LRU, FIFO
	LRU와 FIFO 정책에서는 X개 전까지는 캐시 히트율이 0프로임
	랜덤은 의외로 괜찮은 성능을 보임
	
---
나중에 히트율에서 초기 반드시 발생하는 미스들을 제외하면 
그림표상에서 66.67프로는 사실상 100프로임
```





## 22-2 Beyond Physical Memory: LRU & Clock Algorithm(3/4)



```markdown
# 22.7 Historical 알고리즘의 구현(LRU)
- 링크드 리스트 형태 5>3>4>7, 4가 최근사용, 4>5>3>7 
- 하드웨어의 지원을 받음
- 페이지 접근이 있을 때마다 하드웨어가 메모리의 시간필드를 업데이트함
- 페이지가 접근되면 하드웨어가 시간 필드를 현재 시간으로 설정함
- 페이지 교체 시에 시간 필드를 검사해 가장 오래 전에 사용된 페이지를 찾음

그러나

- 시스템의 페이지 수가 증가하면 시간 필드를 검사하는 과정이 매우 시간 걸림
- 그래서 정확한 제일 오래된 페이지를 찾는 것이 아니라
	어느 정도 오래된 페이지를 찾는 방법 나옴! 개선
	
# 22.8 LRU 정책 근사, Approximating
- LRU를 근사하는 정책 등장
- __use bit(reference bit)라는 하드웨어__ 지원 받음
- 시스템의 각 페이지마다 하나의 use bit 있음
	((use bit는 메모리 어딘가에 존재,구현방법에 따라 페이지 테이블이나 이외의 배열 등등에 위치))
- 페이지가 참조될 때마다(read/write) 하드웨어!에 의해 use bit가 1이 됨
- __!!! 하드웨어는 use bit를 clear, 0으로 바꾸지 않는다
- 		0으로 바꾸는건 운영체제! OS가 한다.__

## Clock 알고리즘
- 모든 페이지가 원형 리스트 형태로 구성
- 시계 바늘이 특정 페이지, pfn 가리킴
- 페이지를 교체해야 할때 운영체제는 현재 바늘 페이지의 use bit 확인
- 1이면 최근에 사용된 페이지, use bit 0으로 바꾸고 넘어감
- 0이면 최근에 사용된 적 없음. 선택! 페이지 교체, swap in

시계바늘은 시계방향으로 돌고 
도는 속도는 페이지 폴트 일어나는 빈도에 비례해서 빨라짐
위에는 랜덤 정책으로도 가능
```

312페이지

```markdown
# 22.9 Dirty pages의 고려
- 시계 알고리즘 추가 개선
- 어떤 페이지가 변경 modified되어 dirty 상태가 되면 기록함
- 변경되지 않은 clean한 ㅍ이지면 추가 io없이 사용가능해 빠르고 좋음
- dirty bit(modified)는 페이지 변경되면 1로 변경
- 시계 알고리즘은 최우선 교체 대상이 use bit=0이고 dirty bit=0인 페이지임
	2순위는 use bit=0, dirty bit=1인 페이지임
```



## 22-2 Beyond Physical Memory: Clock Algorithm Example) (4/4)

PPT20페이지 참고

```markdown
- use bit만 고려한 시계 알고리즘 예시임
- use bit=1은 *로 표기함
- 페이지를 새로 쓰거나 덮어쓰면 시계바늘은 다음으로 넘어간다 *
- hit해서 쓰지 않으면 시계바늘은 유지된다
>>> 시계바늘은 miss일 경우에만 넘어간다.

- 한바퀴 도는 경우 조심
```





## 22-3 Beyond Physical Memory: N'th Chance Algorithm(1/2)

https://www.youtube.com/watch?v=lhuug2jeFEM&list=PLGgVuvaPty_1siPDD1krrWF6ZnyL3tar6

한글교재에는 해당 부분이 생략이오

피피티와 강의만 봐야해요

```markdown
# Implementing LRU
실제 LRU 구현이 어려움

## clock 알고리즘
LRU를 approximate한 걸로
가장 수치적으로 오래된 페이지가 아니라 그냥 어느정도 오래된 페이지를 교체를 하자
(Replace an old page, not the oldest page)

- 하드웨어에 pfn마다 use bit를 추가함

## Nth chance version of Clock 알고리즘
N번의 기회를 주자는 시계 알고리즘의 업뎃 버전

- OS는 페이지마다 counter를 가짐
- 페이지 폴트 발생시 OS는 use bit 체크함
	1 : use bit 0으로 바꾸고 cnt도 clear함 >>> use, cnt 전부 clear
	0 : cnt++, 만약 cnt==N이면 페이지를 교체함
	
__N의 크기 설정 문제?__
large N : LRU에 더 근사해짐, ~1K, 천번까지도 주는데 LRU 굉장히 근사approximation해짐
small N : 더 효율적, free 페이지 찾는데 좀 더 오래 걸리는 단점

__Dirty page는 뭔가__
N의 크기와 dirty 페이지에 응용
- dirty페이지를 교체하는 데는 굉장한 오버헤드, 디스크io시간 등 소요가 큼
	따라서 dirty 페이지를 교체할 때는 기회를 더 준다 > 더티페이지교체최소화

clean page : N=1
dirty page : N=2

(((dirty bit == modified bit
- Modify Bit은 Dirty Bit라고도 하며 write(디스크참조)를 톻해 값이 변경된 데이터를 표시하기 위한 bit)))
(((read,write는 페이지 테이블 엔트리의 protection bit로 세팅)))

# Clock 알고리즘 : details

__PTE에서 사용하는 비트__
use 		: 페이지 사용 중이면 1, 시계 알고리즘에 의해 clear됨
modified     : 페이지가 modified되면 1, 페이지가 디스크에 써지면 clear
valid 		: 프로그램이 이 페이지 참조해도 괜찮다, 페이지 유효
read-only 	: 프로그램이 이 페이지 읽어도 괜찮다, 그러나 modify는 안됨(write)

## 하드웨어가 modified 비트를 지원하지 않는 경우
MMU를 속여서 소프트웨어적으로 처리 가능하다
read-only 비트를 이용함
""" 운영체제가 보는 운영체제가 소프트웨어적으로 처리하는 페이지 테이블에 보조 테이블을 만들고 거기에 진짜 정보를 넣어놓는다. """

- 모든 페이지를 read-only로 세팅 > mmu가 보는 pte!
- write하는 경우 OS로 트랩 걸림
!!! OS가 관리하는 진짜 테이블 보니까 write가 가능하더라 확인!!!
!!! 그럼 지금 write하려나보네, modified bit==1로 세팅 !!!
- OS는 소프트웨어의? modified bit를 1로 설정 ???
- 페이지를 (hw pte를) read-write로 변경
- 페이지가 디스크 참조할 때마다 read-only로 세팅

## 하드웨어가 use bit 지원하지 않는 경우
MMU 속여서 소프트웨어적으로 처리 가능

- 모든 페이지를 invalid로 세팅, 메모리에 있는 페이지도 전부
read 할 때  : (LD) invalid한 페이지에 read하면 OS로 트랩걸림
write 할 때 : (ST) use bit 1로 셋, 페이지를 read-only로 mark, 표시

__modified bit를 얻는 법__
위에 하드웨어 더티비트 안 지원하는 경우랑 같은 방법으로 얻음

- write/invalid/read-only 한 경우들 OS에 트랩 걸림
- use, modified 비트 셋, 페이지를 read-write로 표시mark

>>>__시계바늘이 지나갈 떄, use와 modified비트를 리셋하고 페이지를 invalid한 것으로 표시함__


### 정리
read(LD)

- 모든 페이지 invalid, 트랩 걸림
- 운영체제가 확인하니까 아니다 진짜는 invalid 아니더라
- 이 페이지 레퍼런스, 참조했으니 use bit 1로 세팅
- valid 비트도 1로 세팅
- modified bit 정보도 알아야 하는데 os는 모르니까 위에처럼 read-only로 일단 세팅!
(언젠가 해당 페이지 write하면 mmu 나중에 또 속음, 트랩걸려서 처리하겠지 나중에~)

write(ST)

- 모든 페이지 invalid, 트랩 걸림
- 운영체제가 확인하니까 아니다 진짜는 invalid 아니더라
- 이 페이지 레퍼런스, 참조했으니 use bit 1로 세팅
- write 명령이니 modified 됐구나 알게 되니까 modified bit==1로 세팅
- valid 비트도 1로 세팅
- 나중에 modified 비트 알아내려고 또 트랩 걸리지 않게 read-write로 protection bit도 세팅


>>>__시계바늘이 지나갈 떄, use와 modified비트를 리셋하고 
!!!!!!!!페이지도 invalid한 것으로 표시함__
```



```markdown
# 교수님슬랙
- Clock Algorithm - 커널이 실행하는 SW
- Use bit - MMU가 set 하고(HW) 커널이 Clock Algorithm을 실행하면서 reset(SW).
- MMU가 Use bit를 모르면 Invalid bit를 이용해서 커널이 Use bit를 만들어서 사용
- 이 때 Invalid하면 MMU HW가 이를 발견하여 커널로 Trap
```





# 퀴즈

Replacement Policy 2

```markdown
305페이지
40% 비율로 최적에 가까운 성능을 내지만 항상 그렇지는 않다. ??

2번
- hit인데 시계바늘도 거기임 > use bit 1로 바꾸고 시계바늘은 유지된다.
hit면 바늘유지
```





# 수업중질문

```
캐시가 정확히 어떤 시점에 참조되는가?

mmu에 tlb 있음
가상주소 들어오면 cpu가 mmu에 어디로 갈지 물어봄

캐시에는 주소와 캐시라인, 데이터가 있음
하드웨어적으로 캐시메모리를 먼저 봄

아하 물리주소 pa를 얻고 나서
메모리 접근하기 전에 캐시에 먼저 있는지를 찾아봄
캐시가 더 빠르니까, 메모리엑세스 전에 찾아본다

캐시는 메모리에 접근할때 참조됨

-

캐시되는 부분 물리메모리의 명령어가 2바이트라 칸으로 두칸을 캐싱에 가져간다
```

