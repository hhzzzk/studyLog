# DS_10_KNN

k-nearest neighbors는 가장 가까운 k개의 주변점을 통해 

특성을 유추하는 것이다. 



주변점의 특성은 알고 있기 때문에 이를 통해 특성을 유추할 수 있다.



## 1특징

- 데이터 기반 분석 방법이다.
- 데이터 분포를 가정하지 않는다.
  - 이전에는 선형방정식처럼 점이 선위에 있을 것을 가정했는데 knn은 그렇지 않다. 그저 비슷한 애들끼리 가까이 있을 거라는 전제만 한다.
- 회귀문제, 분류문제 등에 적용 가능하다.



## 1회귀

회귀문제는 특정값을 맞추는 것이다.

- knn의 값을 평균내어 값을 예측한다.
- 가중평균내어 더 가까운 점에 가중치를 더 부여할 수 있다. 이전의 별점 예측과 매우 유사.
  - 별점예측도 knn의 한 종류였다.



## 1분류

점들이 a,b,c 그룹으로 주변점들이 분포되어 있을 때

거리를 k개 봐서 a그룹이 가장 많다면 분류는 a일 것이다.



## 1분류 : 1등이 여럿일 경우

1. 거리에 따라 가중치를 추가한다.
2. 단독 1등이 나올 때까지는 k를 줄인다.

![image](https://github.com/hhzzzk/studyLog/assets/67236054/eec4b1a4-f375-469c-9ce4-1305f4827cb1)

## 1분류 : 데이터가 균일하지 않을 경우?

cut-off를 조절한다.



클래스 불균형은 한 클래스의 데이터 포인트가 다른 클래스에 비해 너무 많을 경우 발생한다.

컷오프를 조절하기 위해 여러 방법이 있는데



전체 데이터의 비율을 고려해 가중치를 매길 수 있다.

각 클래스에 대해 가중치를 계산해 거리 기반 가중평균을 계산한다.

- 예시로 토끼가 3, 고양이가 13개일 경우 토끼의 가중치는 3/16, 고양이는 13/16일 것이다.



## 2적절한 k값 선택하기

데이터마다 적절한 k값이 다르다.

k가 낮으면 불안정한 결과, 오버피팅

k가 높으면 지나친 일반화, 언더피팅

![image](https://github.com/hhzzzk/studyLog/assets/67236054/963f7f7b-d02b-47ce-967d-b44f42584452)

k가 낮으면 경계가 모호하고 지저분하게 분포되어있다. (오버피팅, 해당 케이스에 과몰입)

그에 반해 k가 높자 경계가 단순하고 거의 직선형태다. (너무 일반화, 언더피팅)



## 2방법

가장 좋은 성능을 내는 값을 선택한다.

- k의 값을 1부터 증가시키며 각 점들에 대해 knn을 분류해 오류를 계산한다.
- 가장 오류가 적은 k값을 선택한다.



## 3거리

![image](https://github.com/hhzzzk/studyLog/assets/67236054/5474c6ae-9d49-4fad-ae3a-64a98314399d)

유클리안은 원형으로 분포가 나온다.

맨해튼은 마름모꼴로, n이 무한일 경우 네모꼴로 그래프가 형성된다.

코사인 거리는 유사도와 반대로 작을수록 좋아야 하므로 음수를 붙인다.

​	또 거리는 항상 0보다 커야 하므로 1을 더한다.

![image](https://github.com/hhzzzk/studyLog/assets/67236054/4963f3a7-6ce1-4400-a916-452db3324aab)



![image](https://github.com/hhzzzk/studyLog/assets/67236054/8c3e0fd5-ff9f-4ff0-97f0-f1a2502db25e)

해밍거리는 서로 다른 위치의 비트나 문자의 개수이다.

10101

10011

두개의 해밍거리는 2이다.



## 3KNN 장단점

쉽고 이해하기 직관적

사전학습이 필요없다.

어떤 분포든 상관없음 - 비모수 방식

데이터가 많을 경우 정확도가 올라간다.



단점은

데이터가 많을 경우 연샨량도 올라간다.

- 차원축소 등으로 계산량을 줄일 수 있다. 이후 배움 PCA
- 인덱싱으로 탐색 속도를 향상시킨다.

차원의 저주 : 데이터의 차원이 증가함에 따라 정확도가 급하락한다. 차원이 증가하면 훨씬 더 많은 데이터 필요해진다.



## KNN 인덱싱 방법

 KD트리,

VP트리,

KNN-Graph,

Locality Sensitive Hashing 등이 있다.



