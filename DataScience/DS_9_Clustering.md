# DS_9_Clustering

## 추천시스템

지금까지 배운거 정리



# 지도학습

supervised learning 지도학습은 정답값이 주어진다.

데이터와 데이터의 정답값이 라벨값이 함께 주어져 

훈련시키고 테스트 데이터를 통해 정답을 확인한다.

![image](https://github.com/hhzzzk/studyLog/assets/67236054/001c3e2d-6047-4573-98bf-c5f05f5488bf)



## 비지도학습

정답값이 없고 데이터만 존재한다.

데이터의 구성을 통해 어떤 데이터인지 알아내는 문제이다.

대표적으로 

- 클러스터링
- 차원 축소
- 상관분석, 연관분석



## 클러스터 분석

클러스터 분석은 다차원 공간에서 여러 개의 점들이 존재할 때 = 데이터들

데이터를 군집화, 유사한 것들끼리 묶는, 클러스터 작업을 하는 것이다.



예시로

- 인물 사진 분류 / 스팸 메일 분류 / 사진압축 GIF 등이 있다.

> 유사한 것들끼리 묶기



어떻게 할 수 있을까? 거리계산?

모든 데이터에 다 거리 계산하면 연산횟수 많아서 비용이 너무 든다. 해결?



## K-Means Clustering

반복적인 연산을 통해 데이터를 k개의 클러스터로 분할하는 알고리즘이다.

- 분할법 / 클러스터 개수 k 지정이 필요 / 반복연산 iterative process

4단계

1. 랜덤으로 k개의 중심점 = 센트로이드을 잡는다.
   - 실제 데이터 점이 아님. 정말 랜덤. 
2. 각 점과 센터와 거리계산해서 k개의 클러스터 중 한 개로 귀속시킨다.
3. 각 클러스터에 포함된 점들을 평균내어 새로운 센트로이드를 계산한다.
   - 실제 데이터 점이 아니라 수치로 계산된 점
4. 2,3번을 반복. 클러스터에 변화가 없으면 종료한다.

![image](https://github.com/hhzzzk/studyLog/assets/67236054/29b0d7d0-fa20-47a4-9d67-1d88bdb548db)



## K-Means 한계

local optimum 문제 발생 가능

![image](https://github.com/hhzzzk/studyLog/assets/67236054/18b1b6ce-d535-43cc-85d4-af8125c94cec)

k-means 알고리즘은 초기 중심 선택에 민감하다. 초기 중심 위치에 따라 결과가 크게 달라진다.

이것이 local optimum 문제



local optimu은 초기 중심을 잘못 선택하거나 무작위로 선택한 경우 알고리즘이 수렴할 때 전역 최적해 global optimum이 아닌 지역 최적해 local optimum에 빠질 수 있다는 것이다.

결과가 클러스터링 최적값이 아니다!



## K-Means local optimum 해결법

1. 랜덤으로 초기점 선택할 때 여러 번 반복해서 가장 좋은 결과를 찾는다.
2. Forgy : 가장 많이 사용하는 방법. 실제 데이터의 점들 중에서 랜덤으로 초기점을 선택한다.
3. 사람이 직접 중심점을 지정한다.
4. k-means++ : 점을 선택하고 그 점에서 가장 멀리 떨어진 점들을 초기점으로 삼는다.



## 좋은 클러스터의 기준, k값 선택하기

좋은 클러스터는 분산이 낮아야 한다.

![image](https://github.com/hhzzzk/studyLog/assets/67236054/46b5e684-7690-4d5d-9ec3-c04acb72f480)

목표함수를 다음과 같이 정의한다. > SSE

S는 데이터 집합이고 k는 클러스터의 수다.

Si는 i번째 클러스터에 속한 데이터 집합이다.

실제 데이터와 클러스터 집합의 평균을 빼서 제곱한다. 

제곱한 값을 모두 더한다.





## K값 선택하기

![image](https://github.com/hhzzzk/studyLog/assets/67236054/392cbc81-010b-4c18-8d40-da82eeddecc0)

비용이 아니라 분산이다.

클러스터 수가 많아지면 당연히 분산도 작아진다. 

그러니 그냥 낮아지는게 아니라 갑자기 꺾이듯이 급격하게 낮아지는 k값을 선택한다.



## 다른 클러스터링 방법

다른 방법들에는

- k-medoids: k-means 알고리즘이 이상치에 민감한 문제를 보완
- 계층적 클러스터링
- DBSCAN: 밀도기반 클러스터링 

